//
// Generated by LLVM NVPTX Back-End
//

.version 8.0
.target sm_90a
.address_size 64

	// .globl	_kernel_matmul_fp8_block_fastacc
.extern .shared .align 16 .b8 global_smem[];

.visible .entry _kernel_matmul_fp8_block_fastacc(
	.param .u64 _kernel_matmul_fp8_block_fastacc_param_0,
	.param .u64 _kernel_matmul_fp8_block_fastacc_param_1,
	.param .u64 _kernel_matmul_fp8_block_fastacc_param_2,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_3,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_4,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_5,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_6,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_7,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_8,
	.param .u64 _kernel_matmul_fp8_block_fastacc_param_9,
	.param .u64 _kernel_matmul_fp8_block_fastacc_param_10,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_11,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_12,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_13,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_14,
	.param .u32 _kernel_matmul_fp8_block_fastacc_param_15
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<132>;
	.reg .b16 	%rs<129>;
	.reg .b32 	%r<793>;
	.reg .f32 	%f<3583>;
	.reg .b64 	%rd<270>;
	.loc	1 8 0
$L__func_begin0:
	.loc	1 8 0

	ld.param.u32 	%r46, [_kernel_matmul_fp8_block_fastacc_param_4];
	ld.param.u32 	%r45, [_kernel_matmul_fp8_block_fastacc_param_3];
	ld.param.u64 	%rd38, [_kernel_matmul_fp8_block_fastacc_param_1];
	ld.param.u64 	%rd37, [_kernel_matmul_fp8_block_fastacc_param_0];
$L__tmp0:
	.loc	1 21 10
	// begin inline asm
	mov.u32 %r48, %ctaid.x;
	// end inline asm
	.loc	1 22 10
	// begin inline asm
	mov.u32 %r49, %ctaid.y;
	// end inline asm
	.loc	1 23 10
	add.s32 	%r148, %r45, 127;
	.loc	1 24 10
	shr.s32 	%r149, %r148, 31;
	shr.u32 	%r150, %r149, 25;
	add.s32 	%r151, %r148, %r150;
	shr.s32 	%r152, %r151, 7;
	.loc	1 25 10
	add.s32 	%r153, %r46, 127;
	ld.param.u32 	%r154, [_kernel_matmul_fp8_block_fastacc_param_5];
	.loc	1 26 10
	shr.s32 	%r155, %r153, 31;
	shr.u32 	%r156, %r155, 25;
	add.s32 	%r157, %r153, %r156;
	shr.s32 	%r158, %r157, 7;
	.loc	1 27 10
	shl.b32 	%r160, %r158, 3;
	ld.param.u64 	%rd106, [_kernel_matmul_fp8_block_fastacc_param_9];
	.loc	1 28 10
	div.s32 	%r161, %r48, %r160;
	ld.param.u64 	%rd107, [_kernel_matmul_fp8_block_fastacc_param_10];
	.loc	1 29 10
	shl.b32 	%r162, %r161, 3;
	ld.param.u32 	%r163, [_kernel_matmul_fp8_block_fastacc_param_11];
	.loc	1 30 10
	sub.s32 	%r164, %r152, %r162;
	ld.param.u32 	%r165, [_kernel_matmul_fp8_block_fastacc_param_12];
	.loc	1 31 11
	min.s32 	%r166, %r164, 8;
	.loc	1 32 11
	rem.s32 	%r167, %r48, %r166;
	ld.param.u32 	%r168, [_kernel_matmul_fp8_block_fastacc_param_14];
	.loc	1 33 11
	add.s32 	%r169, %r162, %r167;
	ld.param.u32 	%r170, [_kernel_matmul_fp8_block_fastacc_param_15];
	mul.lo.s32 	%r171, %r161, %r160;
	sub.s32 	%r172, %r48, %r171;
	.loc	1 35 11
	div.s32 	%r173, %r172, %r166;
	.loc	1 36 11
	shl.b32 	%r2, %r169, 7;
	.loc	1 37 11
	mov.u32 	%r3, %tid.x;
	shr.u32 	%r4, %r3, 5;
	bfe.u32 	%r174, %r3, 3, 4;
	or.b32  	%r175, %r174, 16;
	or.b32  	%r176, %r174, 32;
	or.b32  	%r177, %r174, 48;
	or.b32  	%r178, %r174, 64;
	or.b32  	%r179, %r174, 80;
	or.b32  	%r180, %r174, 96;
	or.b32  	%r181, %r174, 112;
	.loc	1 38 11
	shl.b32 	%r182, %r3, 4;
	and.b32  	%r5, %r182, 112;
	.loc	1 45 11
	or.b32  	%r183, %r2, %r174;
	or.b32  	%r184, %r2, %r175;
	or.b32  	%r185, %r2, %r176;
	or.b32  	%r186, %r2, %r177;
	or.b32  	%r187, %r2, %r178;
	or.b32  	%r188, %r2, %r179;
	or.b32  	%r189, %r2, %r180;
	or.b32  	%r190, %r2, %r181;
	.loc	1 49 11
	shl.b32 	%r6, %r173, 7;
	.loc	1 52 11
	or.b32  	%r191, %r6, %r174;
	or.b32  	%r192, %r6, %r175;
	or.b32  	%r193, %r6, %r176;
	or.b32  	%r194, %r6, %r177;
	or.b32  	%r195, %r6, %r178;
	or.b32  	%r196, %r6, %r179;
	or.b32  	%r197, %r6, %r180;
	or.b32  	%r198, %r6, %r181;
	.loc	1 56 11
	rem.s32 	%r199, %r183, %r45;
	rem.s32 	%r200, %r184, %r45;
	rem.s32 	%r201, %r185, %r45;
	rem.s32 	%r202, %r186, %r45;
	rem.s32 	%r203, %r187, %r45;
	rem.s32 	%r204, %r188, %r45;
	rem.s32 	%r205, %r189, %r45;
	rem.s32 	%r206, %r190, %r45;
	.loc	1 59 11
	rem.s32 	%r207, %r191, %r46;
	rem.s32 	%r208, %r192, %r46;
	rem.s32 	%r209, %r193, %r46;
	rem.s32 	%r210, %r194, %r46;
	rem.s32 	%r211, %r195, %r46;
	rem.s32 	%r212, %r196, %r46;
	rem.s32 	%r213, %r197, %r46;
	rem.s32 	%r214, %r198, %r46;
	.loc	1 60 11
	shl.b32 	%r7, %r49, 7;
	.loc	1 63 11
	or.b32  	%r215, %r7, %r5;
	.loc	1 67 11
	mul.lo.s32 	%r8, %r199, %r163;
	mul.lo.s32 	%r9, %r200, %r163;
	mul.lo.s32 	%r10, %r201, %r163;
	mul.lo.s32 	%r11, %r202, %r163;
	mul.lo.s32 	%r12, %r203, %r163;
	mul.lo.s32 	%r13, %r204, %r163;
	mul.lo.s32 	%r14, %r205, %r163;
	mul.lo.s32 	%r15, %r206, %r163;
	.loc	1 71 11
	add.s32 	%r216, %r8, %r215;
	add.s32 	%r217, %r9, %r215;
	add.s32 	%r218, %r10, %r215;
	add.s32 	%r219, %r11, %r215;
	add.s32 	%r220, %r12, %r215;
	add.s32 	%r221, %r13, %r215;
	add.s32 	%r222, %r14, %r215;
	add.s32 	%r223, %r15, %r215;
	.loc	1 73 11
	cvt.s64.s32 	%rd108, %r216;
	add.s64 	%rd40, %rd37, %rd108;
	cvt.s64.s32 	%rd109, %r217;
	add.s64 	%rd41, %rd37, %rd109;
	cvt.s64.s32 	%rd110, %r218;
	add.s64 	%rd42, %rd37, %rd110;
	cvt.s64.s32 	%rd111, %r219;
	add.s64 	%rd43, %rd37, %rd111;
	cvt.s64.s32 	%rd112, %r220;
	add.s64 	%rd44, %rd37, %rd112;
	cvt.s64.s32 	%rd113, %r221;
	add.s64 	%rd45, %rd37, %rd113;
	cvt.s64.s32 	%rd114, %r222;
	add.s64 	%rd46, %rd37, %rd114;
	cvt.s64.s32 	%rd115, %r223;
	add.s64 	%rd47, %rd37, %rd115;
	.loc	1 77 11
	mul.lo.s32 	%r16, %r207, %r165;
	mul.lo.s32 	%r17, %r208, %r165;
	mul.lo.s32 	%r18, %r209, %r165;
	mul.lo.s32 	%r19, %r210, %r165;
	mul.lo.s32 	%r20, %r211, %r165;
	mul.lo.s32 	%r21, %r212, %r165;
	mul.lo.s32 	%r22, %r213, %r165;
	mul.lo.s32 	%r23, %r214, %r165;
	.loc	1 80 11
	add.s32 	%r224, %r16, %r215;
	add.s32 	%r225, %r17, %r215;
	add.s32 	%r226, %r18, %r215;
	add.s32 	%r227, %r19, %r215;
	add.s32 	%r228, %r20, %r215;
	add.s32 	%r229, %r21, %r215;
	add.s32 	%r230, %r22, %r215;
	add.s32 	%r231, %r23, %r215;
	.loc	1 82 11
	cvt.s64.s32 	%rd116, %r224;
	add.s64 	%rd48, %rd38, %rd116;
	cvt.s64.s32 	%rd117, %r225;
	add.s64 	%rd49, %rd38, %rd117;
	cvt.s64.s32 	%rd118, %r226;
	add.s64 	%rd50, %rd38, %rd118;
	cvt.s64.s32 	%rd119, %r227;
	add.s64 	%rd51, %rd38, %rd119;
	cvt.s64.s32 	%rd120, %r228;
	add.s64 	%rd52, %rd38, %rd120;
	cvt.s64.s32 	%rd121, %r229;
	add.s64 	%rd53, %rd38, %rd121;
	cvt.s64.s32 	%rd122, %r230;
	add.s64 	%rd54, %rd38, %rd122;
	cvt.s64.s32 	%rd123, %r231;
	add.s64 	%rd55, %rd38, %rd123;
	.loc	1 83 11
	bfe.s32 	%r232, %r169, 0, 25;
	.loc	1 84 11
	bfe.s32 	%r233, %r173, 0, 25;
	.loc	1 85 11
	add.s32 	%r24, %r154, 127;
	.loc	1 87 11
	mul.lo.s32 	%r237, %r232, %r168;
	.loc	1 88 11
	mul.wide.s32 	%rd124, %r237, 4;
	add.s64 	%rd17, %rd106, %rd124;
	.loc	1 89 11
	mul.lo.s32 	%r238, %r233, %r170;
	.loc	1 90 11
	mul.wide.s32 	%rd125, %r238, 4;
	add.s64 	%rd18, %rd107, %rd125;
	.loc	1 93 11
	setp.gt.s32 	%p49, %r24, 127;
	.loc	1 96 11
	shl.b32 	%r239, %r174, 7;
	shl.b32 	%r240, %r3, 1;
	xor.b32  	%r241, %r182, %r240;
	and.b32  	%r242, %r241, 112;
	or.b32  	%r26, %r239, %r242;
	mov.u32 	%r243, global_smem;
	add.s32 	%r50, %r243, %r26;
	shl.b32 	%r244, %r175, 7;
	or.b32  	%r27, %r244, %r242;
	add.s32 	%r52, %r243, %r27;
	shl.b32 	%r245, %r176, 7;
	or.b32  	%r28, %r245, %r242;
	add.s32 	%r54, %r243, %r28;
	shl.b32 	%r246, %r177, 7;
	or.b32  	%r29, %r246, %r242;
	add.s32 	%r56, %r243, %r29;
	shl.b32 	%r247, %r178, 7;
	or.b32  	%r30, %r247, %r242;
	add.s32 	%r58, %r243, %r30;
	shl.b32 	%r248, %r179, 7;
	or.b32  	%r31, %r248, %r242;
	add.s32 	%r60, %r243, %r31;
	shl.b32 	%r249, %r180, 7;
	or.b32  	%r32, %r249, %r242;
	add.s32 	%r62, %r243, %r32;
	shl.b32 	%r250, %r181, 7;
	or.b32  	%r33, %r250, %r242;
	add.s32 	%r64, %r243, %r33;
	selp.b32 	%r51, 16, 0, %p49;
	mov.pred 	%p54, -1;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r50 + 0 ], [ %rd40 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r52 + 0 ], [ %rd41 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r54 + 0 ], [ %rd42 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r56 + 0 ], [ %rd43 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r58 + 0 ], [ %rd44 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r60 + 0 ], [ %rd45 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r62 + 0 ], [ %rd46 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r64 + 0 ], [ %rd47 + 0 ], 0x10, %r51;
	// end inline asm
	.loc	1 97 11
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 100 11
	add.s32 	%r251, %r243, 65536;
	add.s32 	%r66, %r251, %r26;
	add.s32 	%r68, %r251, %r27;
	add.s32 	%r70, %r251, %r28;
	add.s32 	%r72, %r251, %r29;
	add.s32 	%r74, %r251, %r30;
	add.s32 	%r76, %r251, %r31;
	add.s32 	%r78, %r251, %r32;
	add.s32 	%r80, %r251, %r33;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r66 + 0 ], [ %rd48 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r68 + 0 ], [ %rd49 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r70 + 0 ], [ %rd50 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r72 + 0 ], [ %rd51 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r74 + 0 ], [ %rd52 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r76 + 0 ], [ %rd53 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r78 + 0 ], [ %rd54 + 0 ], 0x10, %r51;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r80 + 0 ], [ %rd55 + 0 ], 0x10, %r51;
	// end inline asm
	.loc	1 101 11
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 102 11
	setp.gt.s32 	%p51, %r24, 255;
	.loc	1 103 11
	add.s64 	%rd56, %rd40, 128;
	add.s64 	%rd57, %rd41, 128;
	add.s64 	%rd58, %rd42, 128;
	add.s64 	%rd59, %rd43, 128;
	add.s64 	%rd60, %rd44, 128;
	add.s64 	%rd61, %rd45, 128;
	add.s64 	%rd62, %rd46, 128;
	add.s64 	%rd63, %rd47, 128;
	.loc	1 104 11
	add.s64 	%rd64, %rd48, 128;
	add.s64 	%rd65, %rd49, 128;
	add.s64 	%rd66, %rd50, 128;
	add.s64 	%rd67, %rd51, 128;
	add.s64 	%rd68, %rd52, 128;
	add.s64 	%rd69, %rd53, 128;
	add.s64 	%rd70, %rd54, 128;
	add.s64 	%rd71, %rd55, 128;
	.loc	1 107 11
	bar.sync 	0;
	add.s32 	%r252, %r243, 16384;
	add.s32 	%r82, %r252, %r26;
	add.s32 	%r84, %r252, %r27;
	add.s32 	%r86, %r252, %r28;
	add.s32 	%r88, %r252, %r29;
	add.s32 	%r90, %r252, %r30;
	add.s32 	%r92, %r252, %r31;
	add.s32 	%r94, %r252, %r32;
	add.s32 	%r96, %r252, %r33;
	selp.b32 	%r83, 16, 0, %p51;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r82 + 0 ], [ %rd56 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r84 + 0 ], [ %rd57 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r86 + 0 ], [ %rd58 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r88 + 0 ], [ %rd59 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r90 + 0 ], [ %rd60 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r92 + 0 ], [ %rd61 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r94 + 0 ], [ %rd62 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r96 + 0 ], [ %rd63 + 0 ], 0x10, %r83;
	// end inline asm
	.loc	1 108 11
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 111 11
	add.s32 	%r253, %r243, 81920;
	add.s32 	%r98, %r253, %r26;
	add.s32 	%r100, %r253, %r27;
	add.s32 	%r102, %r253, %r28;
	add.s32 	%r104, %r253, %r29;
	add.s32 	%r106, %r253, %r30;
	add.s32 	%r108, %r253, %r31;
	add.s32 	%r110, %r253, %r32;
	add.s32 	%r112, %r253, %r33;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r98 + 0 ], [ %rd64 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r100 + 0 ], [ %rd65 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r102 + 0 ], [ %rd66 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r104 + 0 ], [ %rd67 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r106 + 0 ], [ %rd68 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r108 + 0 ], [ %rd69 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r110 + 0 ], [ %rd70 + 0 ], 0x10, %r83;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r112 + 0 ], [ %rd71 + 0 ], 0x10, %r83;
	// end inline asm
	.loc	1 112 11
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 113 11
	setp.gt.s32 	%p52, %r24, 383;
	.loc	1 114 11
	add.s64 	%rd72, %rd40, 256;
	add.s64 	%rd73, %rd41, 256;
	add.s64 	%rd74, %rd42, 256;
	add.s64 	%rd75, %rd43, 256;
	add.s64 	%rd76, %rd44, 256;
	add.s64 	%rd77, %rd45, 256;
	add.s64 	%rd78, %rd46, 256;
	add.s64 	%rd79, %rd47, 256;
	.loc	1 115 11
	add.s64 	%rd80, %rd48, 256;
	add.s64 	%rd81, %rd49, 256;
	add.s64 	%rd82, %rd50, 256;
	add.s64 	%rd83, %rd51, 256;
	add.s64 	%rd84, %rd52, 256;
	add.s64 	%rd85, %rd53, 256;
	add.s64 	%rd86, %rd54, 256;
	add.s64 	%rd87, %rd55, 256;
	.loc	1 118 11
	bar.sync 	0;
	add.s32 	%r254, %r243, 32768;
	add.s32 	%r114, %r254, %r26;
	add.s32 	%r116, %r254, %r27;
	add.s32 	%r118, %r254, %r28;
	add.s32 	%r120, %r254, %r29;
	add.s32 	%r122, %r254, %r30;
	add.s32 	%r124, %r254, %r31;
	add.s32 	%r126, %r254, %r32;
	add.s32 	%r128, %r254, %r33;
	selp.b32 	%r115, 16, 0, %p52;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r114 + 0 ], [ %rd72 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r116 + 0 ], [ %rd73 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r118 + 0 ], [ %rd74 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r120 + 0 ], [ %rd75 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r122 + 0 ], [ %rd76 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r124 + 0 ], [ %rd77 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r126 + 0 ], [ %rd78 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r128 + 0 ], [ %rd79 + 0 ], 0x10, %r115;
	// end inline asm
	.loc	1 119 11
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 122 12
	add.s32 	%r255, %r243, 98304;
	add.s32 	%r130, %r255, %r26;
	add.s32 	%r132, %r255, %r27;
	add.s32 	%r134, %r255, %r28;
	add.s32 	%r136, %r255, %r29;
	add.s32 	%r138, %r255, %r30;
	add.s32 	%r140, %r255, %r31;
	add.s32 	%r142, %r255, %r32;
	add.s32 	%r144, %r255, %r33;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r130 + 0 ], [ %rd80 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r132 + 0 ], [ %rd81 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r134 + 0 ], [ %rd82 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r136 + 0 ], [ %rd83 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r138 + 0 ], [ %rd84 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r140 + 0 ], [ %rd85 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r142 + 0 ], [ %rd86 + 0 ], 0x10, %r115;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r144 + 0 ], [ %rd87 + 0 ], 0x10, %r115;
	// end inline asm
	.loc	1 123 12
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 126 12
	// begin inline asm
	cp.async.wait_group 0x4;
	// end inline asm
	bar.sync 	0;
	.loc	1 127 12
	and.b32  	%r34, %r4, 134217724;
	shfl.sync.idx.b32	%r256, %r34, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	shl.b32 	%r257, %r256, 7;
	and.b32  	%r258, %r257, 384;
	cvt.u64.u32 	%rd126, %r258;
	shr.u32 	%r259, %r243, 4;
	cvt.u64.u32 	%rd127, %r259;
	and.b64  	%rd128, %rd127, 16383;
	add.s64 	%rd129, %rd128, %rd126;
	or.b64  	%rd88, %rd129, 4611686293338849280;
	shr.u32 	%r260, %r251, 4;
	cvt.u64.u32 	%rd130, %r260;
	and.b64  	%rd131, %rd130, 16383;
	or.b64  	%rd89, %rd131, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f841,%f842,%f843,%f844,%f845,%f846,%f847,%f848,%f849,%f850,%f851,%f852,%f853,%f854,%f855,%f856,%f857,%f858,%f859,%f860,%f861,%f862,%f863,%f864,%f865,%f866,%f867,%f868,%f869,%f870,%f871,%f872,%f873,%f874,%f875,%f876,%f877,%f878,%f879,%f880,%f881,%f882,%f883,%f884,%f885,%f886,%f887,%f888,%f889,%f890,%f891,%f892,%f893,%f894,%f895,%f896,%f897,%f898,%f899,%f900,%f901,%f902,%f903,%f904}, %rd88, %rd89, 0, 1, 1;
	// end inline asm
	add.s64 	%rd90, %rd129, 4611686293338849282;
	add.s64 	%rd91, %rd131, 4611686293372403714;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f841,%f842,%f843,%f844,%f845,%f846,%f847,%f848,%f849,%f850,%f851,%f852,%f853,%f854,%f855,%f856,%f857,%f858,%f859,%f860,%f861,%f862,%f863,%f864,%f865,%f866,%f867,%f868,%f869,%f870,%f871,%f872,%f873,%f874,%f875,%f876,%f877,%f878,%f879,%f880,%f881,%f882,%f883,%f884,%f885,%f886,%f887,%f888,%f889,%f890,%f891,%f892,%f893,%f894,%f895,%f896,%f897,%f898,%f899,%f900,%f901,%f902,%f903,%f904}, %rd90, %rd91, 1, 1, 1;
	// end inline asm
	add.s64 	%rd92, %rd129, 4611686293338849284;
	add.s64 	%rd93, %rd131, 4611686293372403716;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f841,%f842,%f843,%f844,%f845,%f846,%f847,%f848,%f849,%f850,%f851,%f852,%f853,%f854,%f855,%f856,%f857,%f858,%f859,%f860,%f861,%f862,%f863,%f864,%f865,%f866,%f867,%f868,%f869,%f870,%f871,%f872,%f873,%f874,%f875,%f876,%f877,%f878,%f879,%f880,%f881,%f882,%f883,%f884,%f885,%f886,%f887,%f888,%f889,%f890,%f891,%f892,%f893,%f894,%f895,%f896,%f897,%f898,%f899,%f900,%f901,%f902,%f903,%f904}, %rd92, %rd93, 1, 1, 1;
	// end inline asm
	add.s64 	%rd94, %rd129, 4611686293338849286;
	add.s64 	%rd95, %rd131, 4611686293372403718;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f841,%f842,%f843,%f844,%f845,%f846,%f847,%f848,%f849,%f850,%f851,%f852,%f853,%f854,%f855,%f856,%f857,%f858,%f859,%f860,%f861,%f862,%f863,%f864,%f865,%f866,%f867,%f868,%f869,%f870,%f871,%f872,%f873,%f874,%f875,%f876,%f877,%f878,%f879,%f880,%f881,%f882,%f883,%f884,%f885,%f886,%f887,%f888,%f889,%f890,%f891,%f892,%f893,%f894,%f895,%f896,%f897,%f898,%f899,%f900,%f901,%f902,%f903,%f904}, %rd94, %rd95, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	// begin inline asm
	// wait for regs: %f841,%f842,%f843,%f844,%f845,%f846,%f847,%f848,%f849,%f850,%f851,%f852,%f853,%f854,%f855,%f856,%f857,%f858,%f859,%f860,%f861,%f862,%f863,%f864,%f865,%f866,%f867,%f868,%f869,%f870,%f871,%f872,%f873,%f874,%f875,%f876,%f877,%f878,%f879,%f880,%f881,%f882,%f883,%f884,%f885,%f886,%f887,%f888,%f889,%f890,%f891,%f892,%f893,%f894,%f895,%f896,%f897,%f898,%f899,%f900,%f901,%f902,%f903,%f904
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	.loc	1 129 12
	shfl.sync.idx.b32	%r261, %r34, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	shl.b32 	%r262, %r261, 7;
	and.b32  	%r263, %r262, 384;
	cvt.u64.u32 	%rd132, %r263;
	add.s32 	%r264, %r243, 8192;
	shr.u32 	%r265, %r264, 4;
	cvt.u64.u32 	%rd133, %r265;
	and.b64  	%rd134, %rd133, 16383;
	add.s64 	%rd135, %rd134, %rd132;
	or.b64  	%rd96, %rd135, 4611686293338849280;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd96, %rd89, 0, 1, 1;
	// end inline asm
	add.s64 	%rd98, %rd135, 4611686293338849282;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd98, %rd91, 1, 1, 1;
	// end inline asm
	add.s64 	%rd100, %rd135, 4611686293338849284;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd100, %rd93, 1, 1, 1;
	// end inline asm
	add.s64 	%rd102, %rd135, 4611686293338849286;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd102, %rd95, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	// begin inline asm
	// wait for regs: %f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	.loc	1 131 12
	mul.wide.s32 	%rd136, %r49, 4;
	add.s64 	%rd104, %rd17, %rd136;
	.loc	1 132 12
	// begin inline asm
	mov.u32 %r146, 0x0;
	@%p49 ld.global.b32 { %r146 }, [ %rd104 + 0 ];
	// end inline asm
	mov.b32 	%f1801, %r146;
	.loc	1 133 12
	add.s64 	%rd105, %rd18, %rd136;
	.loc	1 134 12
	// begin inline asm
	mov.u32 %r147, 0x0;
	@%p49 ld.global.b32 { %r147 }, [ %rd105 + 0 ];
	// end inline asm
	mov.b32 	%f1802, %r147;
	.loc	1 135 12
	mul.f32 	%f3324, %f1801, %f1802;
	.loc	1 136 12
	add.s32 	%r266, %r154, -1;
	setp.lt.u32 	%p53, %r266, 128;
	.loc	1 138 12
	@%p53 bra 	$L__BB0_2;
	.loc	1 130 12
	add.s32 	%r272, %r49, 1;
	.loc	1 141 14
	mul.wide.s32 	%rd139, %r272, 4;
	add.s64 	%rd137, %rd17, %rd139;
	.loc	1 142 14
	// begin inline asm
	mov.u32 %r267, 0x0;
	@%p54 ld.global.b32 { %r267 }, [ %rd137 + 0 ];
	// end inline asm
	mov.b32 	%f1803, %r267;
	.loc	1 143 14
	add.s64 	%rd138, %rd18, %rd139;
	.loc	1 144 14
	// begin inline asm
	mov.u32 %r268, 0x0;
	@%p54 ld.global.b32 { %r268 }, [ %rd138 + 0 ];
	// end inline asm
	mov.b32 	%f1804, %r268;
	.loc	1 145 14
	mul.f32 	%f1805, %f1803, %f1804;
	.loc	1 146 14
	mov.b32 	%r271, %f1805;
	mov.b32 	%r270, %f3324;
	// begin inline asm
	div.full.f32 %r269, %r270, %r271;
	// end inline asm
	mov.b32 	%f3324, %r269;
$L__BB0_2:
	.loc	1 0 14
	ld.param.u32 	%r47, [_kernel_matmul_fp8_block_fastacc_param_13];
	ld.param.u64 	%rd39, [_kernel_matmul_fp8_block_fastacc_param_2];
	.loc	1 124 12
	setp.gt.s32 	%p72, %r24, 511;
	.loc	1 102 11
	setp.lt.s32 	%p73, %r24, 256;
	.loc	1 150 12
	mul.f32 	%f3452, %f841, %f3324;
	mul.f32 	%f3451, %f842, %f3324;
	mul.f32 	%f3450, %f843, %f3324;
	mul.f32 	%f3449, %f844, %f3324;
	mul.f32 	%f3448, %f845, %f3324;
	mul.f32 	%f3447, %f846, %f3324;
	mul.f32 	%f3446, %f847, %f3324;
	mul.f32 	%f3445, %f848, %f3324;
	mul.f32 	%f3444, %f849, %f3324;
	mul.f32 	%f3443, %f850, %f3324;
	mul.f32 	%f3442, %f851, %f3324;
	mul.f32 	%f3441, %f852, %f3324;
	mul.f32 	%f3440, %f853, %f3324;
	mul.f32 	%f3439, %f854, %f3324;
	mul.f32 	%f3438, %f855, %f3324;
	mul.f32 	%f3437, %f856, %f3324;
	mul.f32 	%f3436, %f857, %f3324;
	mul.f32 	%f3435, %f858, %f3324;
	mul.f32 	%f3434, %f859, %f3324;
	mul.f32 	%f3433, %f860, %f3324;
	mul.f32 	%f3432, %f861, %f3324;
	mul.f32 	%f3431, %f862, %f3324;
	mul.f32 	%f3430, %f863, %f3324;
	mul.f32 	%f3429, %f864, %f3324;
	mul.f32 	%f3428, %f865, %f3324;
	mul.f32 	%f3427, %f866, %f3324;
	mul.f32 	%f3426, %f867, %f3324;
	mul.f32 	%f3425, %f868, %f3324;
	mul.f32 	%f3424, %f869, %f3324;
	mul.f32 	%f3423, %f870, %f3324;
	mul.f32 	%f3422, %f871, %f3324;
	mul.f32 	%f3421, %f872, %f3324;
	mul.f32 	%f3420, %f873, %f3324;
	mul.f32 	%f3419, %f874, %f3324;
	mul.f32 	%f3418, %f875, %f3324;
	mul.f32 	%f3417, %f876, %f3324;
	mul.f32 	%f3416, %f877, %f3324;
	mul.f32 	%f3415, %f878, %f3324;
	mul.f32 	%f3414, %f879, %f3324;
	mul.f32 	%f3413, %f880, %f3324;
	mul.f32 	%f3412, %f881, %f3324;
	mul.f32 	%f3411, %f882, %f3324;
	mul.f32 	%f3410, %f883, %f3324;
	mul.f32 	%f3409, %f884, %f3324;
	mul.f32 	%f3408, %f885, %f3324;
	mul.f32 	%f3407, %f886, %f3324;
	mul.f32 	%f3406, %f887, %f3324;
	mul.f32 	%f3405, %f888, %f3324;
	mul.f32 	%f3404, %f889, %f3324;
	mul.f32 	%f3403, %f890, %f3324;
	mul.f32 	%f3402, %f891, %f3324;
	mul.f32 	%f3401, %f892, %f3324;
	mul.f32 	%f3400, %f893, %f3324;
	mul.f32 	%f3399, %f894, %f3324;
	mul.f32 	%f3398, %f895, %f3324;
	mul.f32 	%f3397, %f896, %f3324;
	mul.f32 	%f3396, %f897, %f3324;
	mul.f32 	%f3395, %f898, %f3324;
	mul.f32 	%f3394, %f899, %f3324;
	mul.f32 	%f3393, %f900, %f3324;
	mul.f32 	%f3392, %f901, %f3324;
	mul.f32 	%f3391, %f902, %f3324;
	mul.f32 	%f3390, %f903, %f3324;
	mul.f32 	%f3389, %f904, %f3324;
	.loc	1 151 12
	add.s64 	%rd140, %rd40, 384;
	add.s64 	%rd141, %rd41, 384;
	add.s64 	%rd142, %rd42, 384;
	add.s64 	%rd143, %rd43, 384;
	add.s64 	%rd144, %rd44, 384;
	add.s64 	%rd145, %rd45, 384;
	add.s64 	%rd146, %rd46, 384;
	add.s64 	%rd147, %rd47, 384;
	.loc	1 152 12
	add.s64 	%rd148, %rd48, 384;
	add.s64 	%rd149, %rd49, 384;
	add.s64 	%rd150, %rd50, 384;
	add.s64 	%rd151, %rd51, 384;
	add.s64 	%rd152, %rd52, 384;
	add.s64 	%rd153, %rd53, 384;
	add.s64 	%rd154, %rd54, 384;
	add.s64 	%rd155, %rd55, 384;
	.loc	1 155 12
	bar.sync 	0;
	add.s32 	%r306, %r243, 49152;
	add.s32 	%r273, %r306, %r26;
	add.s32 	%r275, %r306, %r27;
	add.s32 	%r277, %r306, %r28;
	add.s32 	%r279, %r306, %r29;
	add.s32 	%r281, %r306, %r30;
	add.s32 	%r283, %r306, %r31;
	add.s32 	%r285, %r306, %r32;
	add.s32 	%r287, %r306, %r33;
	selp.b32 	%r274, 16, 0, %p72;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r273 + 0 ], [ %rd140 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r275 + 0 ], [ %rd141 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r277 + 0 ], [ %rd142 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r279 + 0 ], [ %rd143 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r281 + 0 ], [ %rd144 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r283 + 0 ], [ %rd145 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r285 + 0 ], [ %rd146 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r287 + 0 ], [ %rd147 + 0 ], 0x10, %r274;
	// end inline asm
	.loc	1 156 12
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 159 12
	add.s32 	%r307, %r243, 114688;
	add.s32 	%r289, %r307, %r26;
	add.s32 	%r291, %r307, %r27;
	add.s32 	%r293, %r307, %r28;
	add.s32 	%r295, %r307, %r29;
	add.s32 	%r297, %r307, %r30;
	add.s32 	%r299, %r307, %r31;
	add.s32 	%r301, %r307, %r32;
	add.s32 	%r303, %r307, %r33;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r289 + 0 ], [ %rd148 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r291 + 0 ], [ %rd149 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r293 + 0 ], [ %rd150 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r295 + 0 ], [ %rd151 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r297 + 0 ], [ %rd152 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r299 + 0 ], [ %rd153 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r301 + 0 ], [ %rd154 + 0 ], 0x10, %r274;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r303 + 0 ], [ %rd155 + 0 ], 0x10, %r274;
	// end inline asm
	.loc	1 160 12
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 163 15
	@%p73 bra 	$L__BB0_7;
	.loc	1 0 15
	shr.s32 	%r234, %r24, 31;
	shr.u32 	%r235, %r234, 25;
	add.s32 	%r236, %r24, %r235;
	shr.s32 	%r25, %r236, 7;
	add.s32 	%r35, %r25, -1;
	add.s32 	%r36, %r25, -4;
	.loc	1 163 15
	add.s32 	%r310, %r23, %r7;
	add.s32 	%r311, %r310, %r5;
	cvt.s64.s32 	%rd157, %r311;
	add.s64 	%rd158, %rd157, %rd38;
	add.s64 	%rd19, %rd158, 512;
	add.s32 	%r312, %r22, %r7;
	add.s32 	%r313, %r312, %r5;
	cvt.s64.s32 	%rd159, %r313;
	add.s64 	%rd160, %rd159, %rd38;
	add.s64 	%rd20, %rd160, 512;
	add.s32 	%r314, %r21, %r7;
	add.s32 	%r315, %r314, %r5;
	cvt.s64.s32 	%rd161, %r315;
	add.s64 	%rd162, %rd161, %rd38;
	add.s64 	%rd21, %rd162, 512;
	add.s32 	%r316, %r20, %r7;
	add.s32 	%r317, %r316, %r5;
	cvt.s64.s32 	%rd163, %r317;
	add.s64 	%rd164, %rd163, %rd38;
	add.s64 	%rd22, %rd164, 512;
	add.s32 	%r318, %r19, %r7;
	add.s32 	%r319, %r318, %r5;
	cvt.s64.s32 	%rd165, %r319;
	add.s64 	%rd166, %rd165, %rd38;
	add.s64 	%rd23, %rd166, 512;
	add.s32 	%r320, %r18, %r7;
	add.s32 	%r321, %r320, %r5;
	cvt.s64.s32 	%rd167, %r321;
	add.s64 	%rd168, %rd167, %rd38;
	add.s64 	%rd24, %rd168, 512;
	add.s32 	%r322, %r17, %r7;
	add.s32 	%r323, %r322, %r5;
	cvt.s64.s32 	%rd169, %r323;
	add.s64 	%rd170, %rd169, %rd38;
	add.s64 	%rd25, %rd170, 512;
	add.s32 	%r324, %r16, %r7;
	add.s32 	%r325, %r324, %r5;
	cvt.s64.s32 	%rd171, %r325;
	add.s64 	%rd172, %rd171, %rd38;
	add.s64 	%rd26, %rd172, 512;
	add.s32 	%r326, %r15, %r7;
	add.s32 	%r327, %r326, %r5;
	cvt.s64.s32 	%rd173, %r327;
	add.s64 	%rd174, %rd173, %rd37;
	add.s64 	%rd27, %rd174, 512;
	add.s32 	%r328, %r14, %r7;
	add.s32 	%r329, %r328, %r5;
	cvt.s64.s32 	%rd175, %r329;
	add.s64 	%rd176, %rd175, %rd37;
	add.s64 	%rd28, %rd176, 512;
	add.s32 	%r330, %r13, %r7;
	add.s32 	%r331, %r330, %r5;
	cvt.s64.s32 	%rd177, %r331;
	add.s64 	%rd178, %rd177, %rd37;
	add.s64 	%rd29, %rd178, 512;
	add.s32 	%r332, %r12, %r7;
	add.s32 	%r333, %r332, %r5;
	cvt.s64.s32 	%rd179, %r333;
	add.s64 	%rd180, %rd179, %rd37;
	add.s64 	%rd30, %rd180, 512;
	add.s32 	%r334, %r11, %r7;
	add.s32 	%r335, %r334, %r5;
	cvt.s64.s32 	%rd181, %r335;
	add.s64 	%rd182, %rd181, %rd37;
	add.s64 	%rd31, %rd182, 512;
	add.s32 	%r336, %r10, %r7;
	add.s32 	%r337, %r336, %r5;
	cvt.s64.s32 	%rd183, %r337;
	add.s64 	%rd184, %rd183, %rd37;
	add.s64 	%rd32, %rd184, 512;
	add.s32 	%r338, %r9, %r7;
	add.s32 	%r339, %r338, %r5;
	cvt.s64.s32 	%rd185, %r339;
	add.s64 	%rd186, %rd185, %rd37;
	add.s64 	%rd33, %rd186, 512;
	add.s32 	%r340, %r8, %r7;
	add.s32 	%r341, %r340, %r5;
	cvt.s64.s32 	%rd187, %r341;
	add.s64 	%rd188, %rd187, %rd37;
	add.s64 	%rd34, %rd188, 512;
	mov.b32 	%r791, 3;
	mov.b32 	%r790, 0;
	mov.u64 	%rd269, 0;
	mov.u32 	%r792, %r790;
	bra.uni 	$L__BB0_4;
$L__BB0_6:
	.loc	1 165 14
	setp.lt.s32 	%p96, %r792, %r36;
	.loc	1 206 14
	mul.f32 	%f3452, %f3452, %f3324;
	mul.f32 	%f3451, %f3451, %f3324;
	mul.f32 	%f3450, %f3450, %f3324;
	mul.f32 	%f3449, %f3449, %f3324;
	mul.f32 	%f3448, %f3448, %f3324;
	mul.f32 	%f3447, %f3447, %f3324;
	mul.f32 	%f3446, %f3446, %f3324;
	mul.f32 	%f3445, %f3445, %f3324;
	mul.f32 	%f3444, %f3444, %f3324;
	mul.f32 	%f3443, %f3443, %f3324;
	mul.f32 	%f3442, %f3442, %f3324;
	mul.f32 	%f3441, %f3441, %f3324;
	mul.f32 	%f3440, %f3440, %f3324;
	mul.f32 	%f3439, %f3439, %f3324;
	mul.f32 	%f3438, %f3438, %f3324;
	mul.f32 	%f3437, %f3437, %f3324;
	mul.f32 	%f3436, %f3436, %f3324;
	mul.f32 	%f3435, %f3435, %f3324;
	mul.f32 	%f3434, %f3434, %f3324;
	mul.f32 	%f3433, %f3433, %f3324;
	mul.f32 	%f3432, %f3432, %f3324;
	mul.f32 	%f3431, %f3431, %f3324;
	mul.f32 	%f3430, %f3430, %f3324;
	mul.f32 	%f3429, %f3429, %f3324;
	mul.f32 	%f3428, %f3428, %f3324;
	mul.f32 	%f3427, %f3427, %f3324;
	mul.f32 	%f3426, %f3426, %f3324;
	mul.f32 	%f3425, %f3425, %f3324;
	mul.f32 	%f3424, %f3424, %f3324;
	mul.f32 	%f3423, %f3423, %f3324;
	mul.f32 	%f3422, %f3422, %f3324;
	mul.f32 	%f3421, %f3421, %f3324;
	mul.f32 	%f3420, %f3420, %f3324;
	mul.f32 	%f3419, %f3419, %f3324;
	mul.f32 	%f3418, %f3418, %f3324;
	mul.f32 	%f3417, %f3417, %f3324;
	mul.f32 	%f3416, %f3416, %f3324;
	mul.f32 	%f3415, %f3415, %f3324;
	mul.f32 	%f3414, %f3414, %f3324;
	mul.f32 	%f3413, %f3413, %f3324;
	mul.f32 	%f3412, %f3412, %f3324;
	mul.f32 	%f3411, %f3411, %f3324;
	mul.f32 	%f3410, %f3410, %f3324;
	mul.f32 	%f3409, %f3409, %f3324;
	mul.f32 	%f3408, %f3408, %f3324;
	mul.f32 	%f3407, %f3407, %f3324;
	mul.f32 	%f3406, %f3406, %f3324;
	mul.f32 	%f3405, %f3405, %f3324;
	mul.f32 	%f3404, %f3404, %f3324;
	mul.f32 	%f3403, %f3403, %f3324;
	mul.f32 	%f3402, %f3402, %f3324;
	mul.f32 	%f3401, %f3401, %f3324;
	mul.f32 	%f3400, %f3400, %f3324;
	mul.f32 	%f3399, %f3399, %f3324;
	mul.f32 	%f3398, %f3398, %f3324;
	mul.f32 	%f3397, %f3397, %f3324;
	mul.f32 	%f3396, %f3396, %f3324;
	mul.f32 	%f3395, %f3395, %f3324;
	mul.f32 	%f3394, %f3394, %f3324;
	mul.f32 	%f3393, %f3393, %f3324;
	mul.f32 	%f3392, %f3392, %f3324;
	mul.f32 	%f3391, %f3391, %f3324;
	mul.f32 	%f3390, %f3390, %f3324;
	mul.f32 	%f3389, %f3389, %f3324;
	.loc	1 207 14
	add.s64 	%rd221, %rd34, %rd269;
	add.s64 	%rd222, %rd33, %rd269;
	add.s64 	%rd223, %rd32, %rd269;
	add.s64 	%rd224, %rd31, %rd269;
	add.s64 	%rd225, %rd30, %rd269;
	add.s64 	%rd226, %rd29, %rd269;
	add.s64 	%rd227, %rd28, %rd269;
	.loc	1 208 14
	add.s64 	%rd228, %rd27, %rd269;
	add.s64 	%rd229, %rd26, %rd269;
	add.s64 	%rd230, %rd25, %rd269;
	add.s64 	%rd231, %rd24, %rd269;
	add.s64 	%rd232, %rd23, %rd269;
	add.s64 	%rd233, %rd22, %rd269;
	add.s64 	%rd234, %rd21, %rd269;
	add.s64 	%rd235, %rd20, %rd269;
	.loc	1 209 14
	add.s64 	%rd236, %rd19, %rd269;
	add.s32 	%r398, %r791, 1;
	.loc	1 210 14
	setp.lt.s32 	%p97, %r398, 4;
	.loc	1 211 14
	selp.b32 	%r791, %r398, 0, %p97;
	.loc	1 214 14
	shl.b32 	%r399, %r791, 14;
	add.s32 	%r401, %r243, %r399;
	.loc	1 216 14
	bar.sync 	0;
	add.s32 	%r366, %r401, %r26;
	add.s32 	%r368, %r401, %r27;
	add.s32 	%r370, %r401, %r28;
	add.s32 	%r372, %r401, %r29;
	add.s32 	%r374, %r401, %r30;
	add.s32 	%r376, %r401, %r31;
	add.s32 	%r378, %r401, %r32;
	add.s32 	%r380, %r401, %r33;
	selp.b32 	%r367, 16, 0, %p96;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r366 + 0 ], [ %rd221 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r368 + 0 ], [ %rd222 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r370 + 0 ], [ %rd223 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r372 + 0 ], [ %rd224 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r374 + 0 ], [ %rd225 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r376 + 0 ], [ %rd226 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r378 + 0 ], [ %rd227 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r380 + 0 ], [ %rd228 + 0 ], 0x10, %r367;
	// end inline asm
	.loc	1 217 14
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 218 14
	add.s32 	%r402, %r401, 65536;
	.loc	1 220 14
	add.s32 	%r382, %r402, %r26;
	add.s32 	%r384, %r402, %r27;
	add.s32 	%r386, %r402, %r28;
	add.s32 	%r388, %r402, %r29;
	add.s32 	%r390, %r402, %r30;
	add.s32 	%r392, %r402, %r31;
	add.s32 	%r394, %r402, %r32;
	add.s32 	%r396, %r402, %r33;
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r382 + 0 ], [ %rd229 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r384 + 0 ], [ %rd230 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r386 + 0 ], [ %rd231 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r388 + 0 ], [ %rd232 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r390 + 0 ], [ %rd233 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r392 + 0 ], [ %rd234 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r394 + 0 ], [ %rd235 + 0 ], 0x10, %r367;
	// end inline asm
	// begin inline asm
	@%p54 cp.async.cg.shared.global [ %r396 + 0 ], [ %rd236 + 0 ], 0x10, %r367;
	// end inline asm
	.loc	1 221 14
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 163 15
	add.s64 	%rd269, %rd269, 128;
	add.s32 	%r792, %r42, -1;
	setp.lt.s32 	%p98, %r792, %r35;
	@%p98 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_7;
$L__BB0_4:
	.loc	1 168 14
	add.s32 	%r344, %r790, 1;
	.loc	1 169 14
	setp.lt.s32 	%p76, %r344, 4;
	.loc	1 170 14
	selp.b32 	%r790, %r344, 0, %p76;
	.loc	1 171 14
	shl.b32 	%r345, %r790, 14;
	add.s32 	%r347, %r243, %r345;
	.loc	1 173 14
	// begin inline asm
	cp.async.wait_group 0x4;
	// end inline asm
	bar.sync 	0;
	.loc	1 174 14
	add.s32 	%r348, %r347, 65536;
	.loc	1 175 14
	shfl.sync.idx.b32	%r349, %r34, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	shl.b32 	%r350, %r349, 7;
	and.b32  	%r351, %r350, 384;
	cvt.u64.u32 	%rd207, %r351;
	shr.u32 	%r352, %r347, 4;
	cvt.u64.u32 	%rd208, %r352;
	and.b64  	%rd209, %rd208, 16383;
	add.s64 	%rd210, %rd209, %rd207;
	or.b64  	%rd189, %rd210, 4611686293338849280;
	shr.u32 	%r353, %r348, 4;
	cvt.u64.u32 	%rd211, %r353;
	and.b64  	%rd212, %rd211, 16383;
	or.b64  	%rd190, %rd212, 4611686293372403712;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f3452,%f3451,%f3450,%f3449,%f3448,%f3447,%f3446,%f3445,%f3444,%f3443,%f3442,%f3441,%f3440,%f3439,%f3438,%f3437,%f3436,%f3435,%f3434,%f3433,%f3432,%f3431,%f3430,%f3429,%f3428,%f3427,%f3426,%f3425,%f3424,%f3423,%f3422,%f3421,%f3420,%f3419,%f3418,%f3417,%f3416,%f3415,%f3414,%f3413,%f3412,%f3411,%f3410,%f3409,%f3408,%f3407,%f3406,%f3405,%f3404,%f3403,%f3402,%f3401,%f3400,%f3399,%f3398,%f3397,%f3396,%f3395,%f3394,%f3393,%f3392,%f3391,%f3390,%f3389}, %rd189, %rd190, 1, 1, 1;
	// end inline asm
	add.s64 	%rd191, %rd210, 4611686293338849282;
	add.s64 	%rd192, %rd212, 4611686293372403714;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f3452,%f3451,%f3450,%f3449,%f3448,%f3447,%f3446,%f3445,%f3444,%f3443,%f3442,%f3441,%f3440,%f3439,%f3438,%f3437,%f3436,%f3435,%f3434,%f3433,%f3432,%f3431,%f3430,%f3429,%f3428,%f3427,%f3426,%f3425,%f3424,%f3423,%f3422,%f3421,%f3420,%f3419,%f3418,%f3417,%f3416,%f3415,%f3414,%f3413,%f3412,%f3411,%f3410,%f3409,%f3408,%f3407,%f3406,%f3405,%f3404,%f3403,%f3402,%f3401,%f3400,%f3399,%f3398,%f3397,%f3396,%f3395,%f3394,%f3393,%f3392,%f3391,%f3390,%f3389}, %rd191, %rd192, 1, 1, 1;
	// end inline asm
	add.s64 	%rd193, %rd210, 4611686293338849284;
	add.s64 	%rd194, %rd212, 4611686293372403716;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f3452,%f3451,%f3450,%f3449,%f3448,%f3447,%f3446,%f3445,%f3444,%f3443,%f3442,%f3441,%f3440,%f3439,%f3438,%f3437,%f3436,%f3435,%f3434,%f3433,%f3432,%f3431,%f3430,%f3429,%f3428,%f3427,%f3426,%f3425,%f3424,%f3423,%f3422,%f3421,%f3420,%f3419,%f3418,%f3417,%f3416,%f3415,%f3414,%f3413,%f3412,%f3411,%f3410,%f3409,%f3408,%f3407,%f3406,%f3405,%f3404,%f3403,%f3402,%f3401,%f3400,%f3399,%f3398,%f3397,%f3396,%f3395,%f3394,%f3393,%f3392,%f3391,%f3390,%f3389}, %rd193, %rd194, 1, 1, 1;
	// end inline asm
	add.s64 	%rd195, %rd210, 4611686293338849286;
	add.s64 	%rd196, %rd212, 4611686293372403718;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f3452,%f3451,%f3450,%f3449,%f3448,%f3447,%f3446,%f3445,%f3444,%f3443,%f3442,%f3441,%f3440,%f3439,%f3438,%f3437,%f3436,%f3435,%f3434,%f3433,%f3432,%f3431,%f3430,%f3429,%f3428,%f3427,%f3426,%f3425,%f3424,%f3423,%f3422,%f3421,%f3420,%f3419,%f3418,%f3417,%f3416,%f3415,%f3414,%f3413,%f3412,%f3411,%f3410,%f3409,%f3408,%f3407,%f3406,%f3405,%f3404,%f3403,%f3402,%f3401,%f3400,%f3399,%f3398,%f3397,%f3396,%f3395,%f3394,%f3393,%f3392,%f3391,%f3390,%f3389}, %rd195, %rd196, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	.loc	1 176 16
	mov.b32 	%f2382, %r347;
	mov.b32 	%f3047, %r348;
	mov.f32 	%f3044, 0f00000001;
	mov.f32 	%f3049, 0f00000080;
	mov.f32 	%f3051, 0f00000000;
	mov.f32 	%f2383, %f3049;
	mov.f32 	%f2389, %f3049;
	mov.f32 	%f2387, %f3047;
	mov.f32 	%f2384, %f3044;
	mov.f32 	%f2388, %f3044;
	mov.f32 	%f2385, %f3051;
	mov.f32 	%f2386, %f3051;
	mov.f32 	%f2390, %f3051;
	mov.f32 	%f2391, %f3051;
	// begin inline asm
	// wait for regs: %f3452,%f3451,%f3450,%f3449,%f3448,%f3447,%f3446,%f3445,%f3444,%f3443,%f3442,%f3441,%f3440,%f3439,%f3438,%f3437,%f3436,%f3435,%f3434,%f3433,%f3432,%f3431,%f3430,%f3429,%f3428,%f3427,%f3426,%f3425,%f3424,%f3423,%f3422,%f3421,%f3420,%f3419,%f3418,%f3417,%f3416,%f3415,%f3414,%f3413,%f3412,%f3411,%f3410,%f3409,%f3408,%f3407,%f3406,%f3405,%f3404,%f3403,%f3402,%f3401,%f3400,%f3399,%f3398,%f3397,%f3396,%f3395,%f3394,%f3393,%f3392,%f3391,%f3390,%f3389,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391
	wgmma.wait_group.sync.aligned 1;
	// end inline asm
	.loc	1 178 14
	mul.f32 	%f2594, %f2594, %f3324;
	mul.f32 	%f2595, %f2595, %f3324;
	mul.f32 	%f2596, %f2596, %f3324;
	mul.f32 	%f2597, %f2597, %f3324;
	mul.f32 	%f2598, %f2598, %f3324;
	mul.f32 	%f2599, %f2599, %f3324;
	mul.f32 	%f2600, %f2600, %f3324;
	mul.f32 	%f2601, %f2601, %f3324;
	mul.f32 	%f2602, %f2602, %f3324;
	mul.f32 	%f2603, %f2603, %f3324;
	mul.f32 	%f2604, %f2604, %f3324;
	mul.f32 	%f2605, %f2605, %f3324;
	mul.f32 	%f2606, %f2606, %f3324;
	mul.f32 	%f2607, %f2607, %f3324;
	mul.f32 	%f2608, %f2608, %f3324;
	mul.f32 	%f2609, %f2609, %f3324;
	mul.f32 	%f2610, %f2610, %f3324;
	mul.f32 	%f2611, %f2611, %f3324;
	mul.f32 	%f2612, %f2612, %f3324;
	mul.f32 	%f2613, %f2613, %f3324;
	mul.f32 	%f2614, %f2614, %f3324;
	mul.f32 	%f2615, %f2615, %f3324;
	mul.f32 	%f2616, %f2616, %f3324;
	mul.f32 	%f2617, %f2617, %f3324;
	mul.f32 	%f2618, %f2618, %f3324;
	mul.f32 	%f2619, %f2619, %f3324;
	mul.f32 	%f2620, %f2620, %f3324;
	mul.f32 	%f2621, %f2621, %f3324;
	mul.f32 	%f2622, %f2622, %f3324;
	mul.f32 	%f2623, %f2623, %f3324;
	mul.f32 	%f2624, %f2624, %f3324;
	mul.f32 	%f2625, %f2625, %f3324;
	mul.f32 	%f2626, %f2626, %f3324;
	mul.f32 	%f2627, %f2627, %f3324;
	mul.f32 	%f2628, %f2628, %f3324;
	mul.f32 	%f2629, %f2629, %f3324;
	mul.f32 	%f2630, %f2630, %f3324;
	mul.f32 	%f2631, %f2631, %f3324;
	mul.f32 	%f2632, %f2632, %f3324;
	mul.f32 	%f2633, %f2633, %f3324;
	mul.f32 	%f2634, %f2634, %f3324;
	mul.f32 	%f2635, %f2635, %f3324;
	mul.f32 	%f2636, %f2636, %f3324;
	mul.f32 	%f2637, %f2637, %f3324;
	mul.f32 	%f2638, %f2638, %f3324;
	mul.f32 	%f2639, %f2639, %f3324;
	mul.f32 	%f2640, %f2640, %f3324;
	mul.f32 	%f2641, %f2641, %f3324;
	mul.f32 	%f2642, %f2642, %f3324;
	mul.f32 	%f2643, %f2643, %f3324;
	mul.f32 	%f2644, %f2644, %f3324;
	mul.f32 	%f2645, %f2645, %f3324;
	mul.f32 	%f2646, %f2646, %f3324;
	mul.f32 	%f2647, %f2647, %f3324;
	mul.f32 	%f2648, %f2648, %f3324;
	mul.f32 	%f2649, %f2649, %f3324;
	mul.f32 	%f2650, %f2650, %f3324;
	mul.f32 	%f2651, %f2651, %f3324;
	mul.f32 	%f2652, %f2652, %f3324;
	mul.f32 	%f2653, %f2653, %f3324;
	mul.f32 	%f2654, %f2654, %f3324;
	mul.f32 	%f2655, %f2655, %f3324;
	mul.f32 	%f2656, %f2656, %f3324;
	mul.f32 	%f2657, %f2657, %f3324;
	.loc	1 179 14
	add.s32 	%r354, %r347, 8192;
	.loc	1 180 14
	shfl.sync.idx.b32	%r355, %r34, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	shl.b32 	%r356, %r355, 7;
	and.b32  	%r357, %r356, 384;
	cvt.u64.u32 	%rd213, %r357;
	shr.u32 	%r358, %r354, 4;
	cvt.u64.u32 	%rd214, %r358;
	and.b64  	%rd215, %rd214, 16383;
	add.s64 	%rd216, %rd215, %rd213;
	or.b64  	%rd197, %rd216, 4611686293338849280;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd197, %rd190, 1, 1, 1;
	// end inline asm
	add.s64 	%rd199, %rd216, 4611686293338849282;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd199, %rd192, 1, 1, 1;
	// end inline asm
	add.s64 	%rd201, %rd216, 4611686293338849284;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd201, %rd194, 1, 1, 1;
	// end inline asm
	add.s64 	%rd203, %rd216, 4611686293338849286;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n128k32.f32.e4m3.e4m3 {%f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657}, %rd203, %rd196, 1, 1, 1;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	.loc	1 181 17
	mov.b32 	%f3042, %r354;
	mov.f32 	%f3045, 0f00000040;
	mov.f32 	%f3043, %f3049;
	mov.f32 	%f3046, %f3051;
	mov.f32 	%f3050, %f3051;
	mov.f32 	%f3048, %f3044;
	// begin inline asm
	// wait for regs: %f2594,%f2595,%f2596,%f2597,%f2598,%f2599,%f2600,%f2601,%f2602,%f2603,%f2604,%f2605,%f2606,%f2607,%f2608,%f2609,%f2610,%f2611,%f2612,%f2613,%f2614,%f2615,%f2616,%f2617,%f2618,%f2619,%f2620,%f2621,%f2622,%f2623,%f2624,%f2625,%f2626,%f2627,%f2628,%f2629,%f2630,%f2631,%f2632,%f2633,%f2634,%f2635,%f2636,%f2637,%f2638,%f2639,%f2640,%f2641,%f2642,%f2643,%f2644,%f2645,%f2646,%f2647,%f2648,%f2649,%f2650,%f2651,%f2652,%f2653,%f2654,%f2655,%f2656,%f2657,%f3042,%f3043,%f3044,%f3045,%f3046,%f3047,%f3048,%f3049,%f3050,%f3051
	wgmma.wait_group.sync.aligned 1;
	// end inline asm
	.loc	1 186 14
	add.s32 	%r41, %r49, %r792;
	add.s32 	%r359, %r41, 1;
	mul.wide.s32 	%rd217, %r359, 4;
	add.s64 	%rd205, %rd17, %rd217;
	.loc	1 187 14
	// begin inline asm
	mov.u32 %r342, 0x0;
	@%p54 ld.global.b32 { %r342 }, [ %rd205 + 0 ];
	// end inline asm
	mov.b32 	%f3126, %r342;
	.loc	1 188 14
	add.s64 	%rd206, %rd18, %rd217;
	.loc	1 189 14
	// begin inline asm
	mov.u32 %r343, 0x0;
	@%p54 ld.global.b32 { %r343 }, [ %rd206 + 0 ];
	// end inline asm
	mov.b32 	%f3127, %r343;
	.loc	1 190 14
	mul.f32 	%f3324, %f3126, %f3127;
	.loc	1 192 14
	add.s32 	%r42, %r792, 2;
	setp.eq.s32 	%p77, %r42, %r25;
	.loc	1 194 14
	@%p77 bra 	$L__BB0_6;
	.loc	1 197 16
	add.s32 	%r365, %r41, 2;
	mul.wide.s32 	%rd220, %r365, 4;
	add.s64 	%rd218, %rd17, %rd220;
	.loc	1 198 16
	// begin inline asm
	mov.u32 %r360, 0x0;
	@%p54 ld.global.b32 { %r360 }, [ %rd218 + 0 ];
	// end inline asm
	mov.b32 	%f3128, %r360;
	.loc	1 199 16
	add.s64 	%rd219, %rd18, %rd220;
	.loc	1 200 16
	// begin inline asm
	mov.u32 %r361, 0x0;
	@%p54 ld.global.b32 { %r361 }, [ %rd219 + 0 ];
	// end inline asm
	mov.b32 	%f3129, %r361;
	.loc	1 201 16
	mul.f32 	%f3130, %f3128, %f3129;
	.loc	1 202 16
	mov.b32 	%r364, %f3130;
	mov.b32 	%r363, %f3324;
	// begin inline asm
	div.full.f32 %r362, %r363, %r364;
	// end inline asm
	mov.b32 	%f3324, %r362;
	bra.uni 	$L__BB0_6;
$L__BB0_7:
	.loc	1 42 11
	shl.b32 	%r675, %r3, 3;
	and.b32  	%r676, %r675, 120;
	.loc	1 53 11
	or.b32  	%r677, %r6, %r676;
	.loc	1 39 11
	bfe.u32 	%r678, %r3, 4, 1;
	bfe.u32 	%r679, %r3, 4, 3;
	.loc	1 48 11
	or.b32  	%r680, %r679, %r2;
	or.b32  	%r681, %r680, 120;
	or.b32  	%r682, %r680, 112;
	or.b32  	%r683, %r680, 104;
	or.b32  	%r684, %r680, 96;
	or.b32  	%r685, %r680, 88;
	or.b32  	%r686, %r680, 80;
	or.b32  	%r687, %r680, 72;
	or.b32  	%r688, %r680, 64;
	.loc	1 46 11
	or.b32  	%r689, %r680, 56;
	or.b32  	%r690, %r680, 48;
	or.b32  	%r691, %r680, 40;
	or.b32  	%r692, %r680, 32;
	or.b32  	%r693, %r680, 24;
	or.b32  	%r694, %r680, 16;
	or.b32  	%r695, %r680, 8;
	.loc	1 225 12
	mov.f32 	%f3169, %f2632;
	mov.f32 	%f3131, %f2594;
	mov.f32 	%f3176, %f2639;
	mov.f32 	%f3138, %f2601;
	mov.f32 	%f3183, %f2646;
	mov.f32 	%f3145, %f2608;
	mov.f32 	%f3190, %f2653;
	mov.f32 	%f3152, %f2615;
	mov.f32 	%f3159, %f2622;
	mov.f32 	%f3166, %f2629;
	mov.f32 	%f3173, %f2636;
	mov.f32 	%f3135, %f2598;
	mov.f32 	%f3180, %f2643;
	mov.f32 	%f3142, %f2605;
	mov.f32 	%f3187, %f2650;
	mov.f32 	%f3149, %f2612;
	mov.f32 	%f3194, %f2657;
	mov.f32 	%f3156, %f2619;
	mov.f32 	%f3163, %f2626;
	mov.f32 	%f3170, %f2633;
	mov.f32 	%f3132, %f2595;
	mov.f32 	%f3177, %f2640;
	mov.f32 	%f3139, %f2602;
	mov.f32 	%f3184, %f2647;
	mov.f32 	%f3146, %f2609;
	mov.f32 	%f3191, %f2654;
	mov.f32 	%f3153, %f2616;
	mov.f32 	%f3160, %f2623;
	mov.f32 	%f3167, %f2630;
	mov.f32 	%f3174, %f2637;
	mov.f32 	%f3136, %f2599;
	mov.f32 	%f3181, %f2644;
	mov.f32 	%f3143, %f2606;
	mov.f32 	%f3188, %f2651;
	mov.f32 	%f3150, %f2613;
	mov.f32 	%f3157, %f2620;
	mov.f32 	%f3164, %f2627;
	mov.f32 	%f3171, %f2634;
	mov.f32 	%f3133, %f2596;
	mov.f32 	%f3178, %f2641;
	mov.f32 	%f3140, %f2603;
	mov.f32 	%f3185, %f2648;
	mov.f32 	%f3147, %f2610;
	mov.f32 	%f3192, %f2655;
	mov.f32 	%f3154, %f2617;
	mov.f32 	%f3161, %f2624;
	mov.f32 	%f3168, %f2631;
	mov.f32 	%f3175, %f2638;
	mov.f32 	%f3137, %f2600;
	mov.f32 	%f3182, %f2645;
	mov.f32 	%f3144, %f2607;
	mov.f32 	%f3189, %f2652;
	mov.f32 	%f3151, %f2614;
	mov.f32 	%f3158, %f2621;
	mov.f32 	%f3165, %f2628;
	mov.f32 	%f3172, %f2635;
	mov.f32 	%f3134, %f2597;
	mov.f32 	%f3179, %f2642;
	mov.f32 	%f3141, %f2604;
	mov.f32 	%f3186, %f2649;
	mov.f32 	%f3148, %f2611;
	mov.f32 	%f3193, %f2656;
	mov.f32 	%f3155, %f2618;
	mov.f32 	%f3162, %f2625;
	// begin inline asm
	// wait for regs: %f3131,%f3132,%f3133,%f3134,%f3135,%f3136,%f3137,%f3138,%f3139,%f3140,%f3141,%f3142,%f3143,%f3144,%f3145,%f3146,%f3147,%f3148,%f3149,%f3150,%f3151,%f3152,%f3153,%f3154,%f3155,%f3156,%f3157,%f3158,%f3159,%f3160,%f3161,%f3162,%f3163,%f3164,%f3165,%f3166,%f3167,%f3168,%f3169,%f3170,%f3171,%f3172,%f3173,%f3174,%f3175,%f3176,%f3177,%f3178,%f3179,%f3180,%f3181,%f3182,%f3183,%f3184,%f3185,%f3186,%f3187,%f3188,%f3189,%f3190,%f3191,%f3192,%f3193,%f3194
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	.loc	1 226 12
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 229 12
	mov.b32 	%r403, %f3452;
	// begin inline asm
	cvt.rn.bf16.f32 %rs1, %r403;
	// end inline asm
	mov.b32 	%r404, %f3451;
	// begin inline asm
	cvt.rn.bf16.f32 %rs2, %r404;
	// end inline asm
	mov.b32 	%r405, %f3450;
	// begin inline asm
	cvt.rn.bf16.f32 %rs3, %r405;
	// end inline asm
	mov.b32 	%r406, %f3449;
	// begin inline asm
	cvt.rn.bf16.f32 %rs4, %r406;
	// end inline asm
	mov.b32 	%r407, %f3448;
	// begin inline asm
	cvt.rn.bf16.f32 %rs5, %r407;
	// end inline asm
	mov.b32 	%r408, %f3447;
	// begin inline asm
	cvt.rn.bf16.f32 %rs6, %r408;
	// end inline asm
	mov.b32 	%r409, %f3446;
	// begin inline asm
	cvt.rn.bf16.f32 %rs7, %r409;
	// end inline asm
	mov.b32 	%r410, %f3445;
	// begin inline asm
	cvt.rn.bf16.f32 %rs8, %r410;
	// end inline asm
	mov.b32 	%r411, %f3444;
	// begin inline asm
	cvt.rn.bf16.f32 %rs9, %r411;
	// end inline asm
	mov.b32 	%r412, %f3443;
	// begin inline asm
	cvt.rn.bf16.f32 %rs10, %r412;
	// end inline asm
	mov.b32 	%r413, %f3442;
	// begin inline asm
	cvt.rn.bf16.f32 %rs11, %r413;
	// end inline asm
	mov.b32 	%r414, %f3441;
	// begin inline asm
	cvt.rn.bf16.f32 %rs12, %r414;
	// end inline asm
	mov.b32 	%r415, %f3440;
	// begin inline asm
	cvt.rn.bf16.f32 %rs13, %r415;
	// end inline asm
	mov.b32 	%r416, %f3439;
	// begin inline asm
	cvt.rn.bf16.f32 %rs14, %r416;
	// end inline asm
	mov.b32 	%r417, %f3438;
	// begin inline asm
	cvt.rn.bf16.f32 %rs15, %r417;
	// end inline asm
	mov.b32 	%r418, %f3437;
	// begin inline asm
	cvt.rn.bf16.f32 %rs16, %r418;
	// end inline asm
	mov.b32 	%r419, %f3436;
	// begin inline asm
	cvt.rn.bf16.f32 %rs17, %r419;
	// end inline asm
	mov.b32 	%r420, %f3435;
	// begin inline asm
	cvt.rn.bf16.f32 %rs18, %r420;
	// end inline asm
	mov.b32 	%r421, %f3434;
	// begin inline asm
	cvt.rn.bf16.f32 %rs19, %r421;
	// end inline asm
	mov.b32 	%r422, %f3433;
	// begin inline asm
	cvt.rn.bf16.f32 %rs20, %r422;
	// end inline asm
	mov.b32 	%r423, %f3432;
	// begin inline asm
	cvt.rn.bf16.f32 %rs21, %r423;
	// end inline asm
	mov.b32 	%r424, %f3431;
	// begin inline asm
	cvt.rn.bf16.f32 %rs22, %r424;
	// end inline asm
	mov.b32 	%r425, %f3430;
	// begin inline asm
	cvt.rn.bf16.f32 %rs23, %r425;
	// end inline asm
	mov.b32 	%r426, %f3429;
	// begin inline asm
	cvt.rn.bf16.f32 %rs24, %r426;
	// end inline asm
	mov.b32 	%r427, %f3428;
	// begin inline asm
	cvt.rn.bf16.f32 %rs25, %r427;
	// end inline asm
	mov.b32 	%r428, %f3427;
	// begin inline asm
	cvt.rn.bf16.f32 %rs26, %r428;
	// end inline asm
	mov.b32 	%r429, %f3426;
	// begin inline asm
	cvt.rn.bf16.f32 %rs27, %r429;
	// end inline asm
	mov.b32 	%r430, %f3425;
	// begin inline asm
	cvt.rn.bf16.f32 %rs28, %r430;
	// end inline asm
	mov.b32 	%r431, %f3424;
	// begin inline asm
	cvt.rn.bf16.f32 %rs29, %r431;
	// end inline asm
	mov.b32 	%r432, %f3423;
	// begin inline asm
	cvt.rn.bf16.f32 %rs30, %r432;
	// end inline asm
	mov.b32 	%r433, %f3422;
	// begin inline asm
	cvt.rn.bf16.f32 %rs31, %r433;
	// end inline asm
	mov.b32 	%r434, %f3421;
	// begin inline asm
	cvt.rn.bf16.f32 %rs32, %r434;
	// end inline asm
	mov.b32 	%r435, %f3420;
	// begin inline asm
	cvt.rn.bf16.f32 %rs33, %r435;
	// end inline asm
	mov.b32 	%r436, %f3419;
	// begin inline asm
	cvt.rn.bf16.f32 %rs34, %r436;
	// end inline asm
	mov.b32 	%r437, %f3418;
	// begin inline asm
	cvt.rn.bf16.f32 %rs35, %r437;
	// end inline asm
	mov.b32 	%r438, %f3417;
	// begin inline asm
	cvt.rn.bf16.f32 %rs36, %r438;
	// end inline asm
	mov.b32 	%r439, %f3416;
	// begin inline asm
	cvt.rn.bf16.f32 %rs37, %r439;
	// end inline asm
	mov.b32 	%r440, %f3415;
	// begin inline asm
	cvt.rn.bf16.f32 %rs38, %r440;
	// end inline asm
	mov.b32 	%r441, %f3414;
	// begin inline asm
	cvt.rn.bf16.f32 %rs39, %r441;
	// end inline asm
	mov.b32 	%r442, %f3413;
	// begin inline asm
	cvt.rn.bf16.f32 %rs40, %r442;
	// end inline asm
	mov.b32 	%r443, %f3412;
	// begin inline asm
	cvt.rn.bf16.f32 %rs41, %r443;
	// end inline asm
	mov.b32 	%r444, %f3411;
	// begin inline asm
	cvt.rn.bf16.f32 %rs42, %r444;
	// end inline asm
	mov.b32 	%r445, %f3410;
	// begin inline asm
	cvt.rn.bf16.f32 %rs43, %r445;
	// end inline asm
	mov.b32 	%r446, %f3409;
	// begin inline asm
	cvt.rn.bf16.f32 %rs44, %r446;
	// end inline asm
	mov.b32 	%r447, %f3408;
	// begin inline asm
	cvt.rn.bf16.f32 %rs45, %r447;
	// end inline asm
	mov.b32 	%r448, %f3407;
	// begin inline asm
	cvt.rn.bf16.f32 %rs46, %r448;
	// end inline asm
	mov.b32 	%r449, %f3406;
	// begin inline asm
	cvt.rn.bf16.f32 %rs47, %r449;
	// end inline asm
	mov.b32 	%r450, %f3405;
	// begin inline asm
	cvt.rn.bf16.f32 %rs48, %r450;
	// end inline asm
	mov.b32 	%r451, %f3404;
	// begin inline asm
	cvt.rn.bf16.f32 %rs49, %r451;
	// end inline asm
	mov.b32 	%r452, %f3403;
	// begin inline asm
	cvt.rn.bf16.f32 %rs50, %r452;
	// end inline asm
	mov.b32 	%r453, %f3402;
	// begin inline asm
	cvt.rn.bf16.f32 %rs51, %r453;
	// end inline asm
	mov.b32 	%r454, %f3401;
	// begin inline asm
	cvt.rn.bf16.f32 %rs52, %r454;
	// end inline asm
	mov.b32 	%r455, %f3400;
	// begin inline asm
	cvt.rn.bf16.f32 %rs53, %r455;
	// end inline asm
	mov.b32 	%r456, %f3399;
	// begin inline asm
	cvt.rn.bf16.f32 %rs54, %r456;
	// end inline asm
	mov.b32 	%r457, %f3398;
	// begin inline asm
	cvt.rn.bf16.f32 %rs55, %r457;
	// end inline asm
	mov.b32 	%r458, %f3397;
	// begin inline asm
	cvt.rn.bf16.f32 %rs56, %r458;
	// end inline asm
	mov.b32 	%r459, %f3396;
	// begin inline asm
	cvt.rn.bf16.f32 %rs57, %r459;
	// end inline asm
	mov.b32 	%r460, %f3395;
	// begin inline asm
	cvt.rn.bf16.f32 %rs58, %r460;
	// end inline asm
	mov.b32 	%r461, %f3394;
	// begin inline asm
	cvt.rn.bf16.f32 %rs59, %r461;
	// end inline asm
	mov.b32 	%r462, %f3393;
	// begin inline asm
	cvt.rn.bf16.f32 %rs60, %r462;
	// end inline asm
	mov.b32 	%r463, %f3392;
	// begin inline asm
	cvt.rn.bf16.f32 %rs61, %r463;
	// end inline asm
	mov.b32 	%r464, %f3391;
	// begin inline asm
	cvt.rn.bf16.f32 %rs62, %r464;
	// end inline asm
	mov.b32 	%r465, %f3390;
	// begin inline asm
	cvt.rn.bf16.f32 %rs63, %r465;
	// end inline asm
	mov.b32 	%r466, %f3389;
	// begin inline asm
	cvt.rn.bf16.f32 %rs64, %r466;
	// end inline asm
	.loc	1 232 12
	shl.b32 	%r696, %r47, 3;
	.loc	1 236 12
	mad.lo.s32 	%r697, %r680, %r47, %r677;
	add.s32 	%r698, %r697, %r696;
	add.s32 	%r699, %r698, %r696;
	add.s32 	%r700, %r699, %r696;
	add.s32 	%r701, %r700, %r696;
	add.s32 	%r702, %r701, %r696;
	add.s32 	%r703, %r702, %r696;
	add.s32 	%r704, %r703, %r696;
	.loc	1 238 12
	mul.wide.s32 	%rd253, %r697, 2;
	add.s64 	%rd237, %rd39, %rd253;
	mul.wide.s32 	%rd254, %r698, 2;
	add.s64 	%rd238, %rd39, %rd254;
	mul.wide.s32 	%rd255, %r699, 2;
	add.s64 	%rd239, %rd39, %rd255;
	mul.wide.s32 	%rd256, %r700, 2;
	add.s64 	%rd240, %rd39, %rd256;
	mul.wide.s32 	%rd257, %r701, 2;
	add.s64 	%rd241, %rd39, %rd257;
	mul.wide.s32 	%rd258, %r702, 2;
	add.s64 	%rd242, %rd39, %rd258;
	mul.wide.s32 	%rd259, %r703, 2;
	add.s64 	%rd243, %rd39, %rd259;
	mul.wide.s32 	%rd260, %r704, 2;
	add.s64 	%rd244, %rd39, %rd260;
	.loc	1 239 12
	setp.lt.s32 	%p115, %r680, %r45;
	setp.lt.s32 	%p116, %r695, %r45;
	setp.lt.s32 	%p117, %r694, %r45;
	setp.lt.s32 	%p118, %r693, %r45;
	setp.lt.s32 	%p119, %r692, %r45;
	setp.lt.s32 	%p120, %r691, %r45;
	setp.lt.s32 	%p121, %r690, %r45;
	setp.lt.s32 	%p122, %r689, %r45;
	.loc	1 241 12
	setp.lt.s32 	%p123, %r677, %r46;
	.loc	1 245 12
	and.pred  	%p99, %p115, %p123;
	and.pred  	%p100, %p116, %p123;
	and.pred  	%p101, %p117, %p123;
	and.pred  	%p102, %p118, %p123;
	and.pred  	%p103, %p119, %p123;
	and.pred  	%p104, %p120, %p123;
	and.pred  	%p105, %p121, %p123;
	and.pred  	%p106, %p122, %p123;
	.loc	1 246 12
	and.b32  	%r705, %r4, 3;
	and.b32  	%r706, %r3, 15;
	shr.u32 	%r707, %r3, 1;
	and.b32  	%r708, %r707, 8;
	mad.lo.s32 	%r709, %r706, 136, %r708;
	mad.lo.s32 	%r710, %r705, 2176, %r709;
	mov.b32 	%r711, {%rs1, %rs2};
	mov.b32 	%r712, {%rs3, %rs4};
	mov.b32 	%r713, {%rs5, %rs6};
	mov.b32 	%r714, {%rs7, %rs8};
	shl.b32 	%r715, %r710, 1;
	add.s32 	%r467, %r243, %r715;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r467], {%r711, %r712, %r713, %r714};
	// end inline asm
	mov.b32 	%r717, {%rs9, %rs10};
	mov.b32 	%r718, {%rs11, %rs12};
	mov.b32 	%r719, {%rs13, %rs14};
	mov.b32 	%r720, {%rs15, %rs16};
	add.s32 	%r472, %r467, 32;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r472], {%r717, %r718, %r719, %r720};
	// end inline asm
	mov.b32 	%r721, {%rs17, %rs18};
	mov.b32 	%r722, {%rs19, %rs20};
	mov.b32 	%r723, {%rs21, %rs22};
	mov.b32 	%r724, {%rs23, %rs24};
	add.s32 	%r477, %r467, 64;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r477], {%r721, %r722, %r723, %r724};
	// end inline asm
	mov.b32 	%r725, {%rs25, %rs26};
	mov.b32 	%r726, {%rs27, %rs28};
	mov.b32 	%r727, {%rs29, %rs30};
	mov.b32 	%r728, {%rs31, %rs32};
	add.s32 	%r482, %r467, 96;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r482], {%r725, %r726, %r727, %r728};
	// end inline asm
	mov.b32 	%r729, {%rs33, %rs34};
	mov.b32 	%r730, {%rs35, %rs36};
	mov.b32 	%r731, {%rs37, %rs38};
	mov.b32 	%r732, {%rs39, %rs40};
	add.s32 	%r487, %r467, 128;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r487], {%r729, %r730, %r731, %r732};
	// end inline asm
	mov.b32 	%r733, {%rs41, %rs42};
	mov.b32 	%r734, {%rs43, %rs44};
	mov.b32 	%r735, {%rs45, %rs46};
	mov.b32 	%r736, {%rs47, %rs48};
	add.s32 	%r492, %r467, 160;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r492], {%r733, %r734, %r735, %r736};
	// end inline asm
	mov.b32 	%r737, {%rs49, %rs50};
	mov.b32 	%r738, {%rs51, %rs52};
	mov.b32 	%r739, {%rs53, %rs54};
	mov.b32 	%r740, {%rs55, %rs56};
	add.s32 	%r497, %r467, 192;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r497], {%r737, %r738, %r739, %r740};
	// end inline asm
	mov.b32 	%r741, {%rs57, %rs58};
	mov.b32 	%r742, {%rs59, %rs60};
	mov.b32 	%r743, {%rs61, %rs62};
	mov.b32 	%r744, {%rs63, %rs64};
	add.s32 	%r502, %r467, 224;
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r502], {%r741, %r742, %r743, %r744};
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r745, %r705, 1;
	or.b32  	%r746, %r745, %r678;
	mad.lo.s32 	%r747, %r746, 136, %r676;
	shl.b32 	%r748, %r747, 1;
	add.s32 	%r749, %r243, %r748;
	ld.shared.v4.u32 	{%r507, %r508, %r509, %r510}, [%r749];
	ld.shared.v4.u32 	{%r511, %r512, %r513, %r514}, [%r749+2176];
	ld.shared.v4.u32 	{%r515, %r516, %r517, %r518}, [%r749+4352];
	ld.shared.v4.u32 	{%r519, %r520, %r521, %r522}, [%r749+6528];
	ld.shared.v4.u32 	{%r523, %r524, %r525, %r526}, [%r749+8704];
	ld.shared.v4.u32 	{%r527, %r528, %r529, %r530}, [%r749+10880];
	ld.shared.v4.u32 	{%r531, %r532, %r533, %r534}, [%r749+13056];
	ld.shared.v4.u32 	{%r535, %r536, %r537, %r538}, [%r749+15232];
	.loc	1 247 5
	// begin inline asm
	@%p99 st.global.v4.b32 [ %rd237 + 0 ], { %r507, %r508, %r509, %r510 };
	// end inline asm
	// begin inline asm
	@%p100 st.global.v4.b32 [ %rd238 + 0 ], { %r511, %r512, %r513, %r514 };
	// end inline asm
	// begin inline asm
	@%p101 st.global.v4.b32 [ %rd239 + 0 ], { %r515, %r516, %r517, %r518 };
	// end inline asm
	// begin inline asm
	@%p102 st.global.v4.b32 [ %rd240 + 0 ], { %r519, %r520, %r521, %r522 };
	// end inline asm
	// begin inline asm
	@%p103 st.global.v4.b32 [ %rd241 + 0 ], { %r523, %r524, %r525, %r526 };
	// end inline asm
	// begin inline asm
	@%p104 st.global.v4.b32 [ %rd242 + 0 ], { %r527, %r528, %r529, %r530 };
	// end inline asm
	// begin inline asm
	@%p105 st.global.v4.b32 [ %rd243 + 0 ], { %r531, %r532, %r533, %r534 };
	// end inline asm
	// begin inline asm
	@%p106 st.global.v4.b32 [ %rd244 + 0 ], { %r535, %r536, %r537, %r538 };
	// end inline asm
	.loc	1 250 13
	mul.f32 	%f3259, %f2594, %f3324;
	mul.f32 	%f3260, %f2595, %f3324;
	mul.f32 	%f3261, %f2596, %f3324;
	mul.f32 	%f3262, %f2597, %f3324;
	mul.f32 	%f3263, %f2598, %f3324;
	mul.f32 	%f3264, %f2599, %f3324;
	mul.f32 	%f3265, %f2600, %f3324;
	mul.f32 	%f3266, %f2601, %f3324;
	mul.f32 	%f3267, %f2602, %f3324;
	mul.f32 	%f3268, %f2603, %f3324;
	mul.f32 	%f3269, %f2604, %f3324;
	mul.f32 	%f3270, %f2605, %f3324;
	mul.f32 	%f3271, %f2606, %f3324;
	mul.f32 	%f3272, %f2607, %f3324;
	mul.f32 	%f3273, %f2608, %f3324;
	mul.f32 	%f3274, %f2609, %f3324;
	mul.f32 	%f3275, %f2610, %f3324;
	mul.f32 	%f3276, %f2611, %f3324;
	mul.f32 	%f3277, %f2612, %f3324;
	mul.f32 	%f3278, %f2613, %f3324;
	mul.f32 	%f3279, %f2614, %f3324;
	mul.f32 	%f3280, %f2615, %f3324;
	mul.f32 	%f3281, %f2616, %f3324;
	mul.f32 	%f3282, %f2617, %f3324;
	mul.f32 	%f3283, %f2618, %f3324;
	mul.f32 	%f3284, %f2619, %f3324;
	mul.f32 	%f3285, %f2620, %f3324;
	mul.f32 	%f3286, %f2621, %f3324;
	mul.f32 	%f3287, %f2622, %f3324;
	mul.f32 	%f3288, %f2623, %f3324;
	mul.f32 	%f3289, %f2624, %f3324;
	mul.f32 	%f3290, %f2625, %f3324;
	mul.f32 	%f3291, %f2626, %f3324;
	mul.f32 	%f3292, %f2627, %f3324;
	mul.f32 	%f3293, %f2628, %f3324;
	mul.f32 	%f3294, %f2629, %f3324;
	mul.f32 	%f3295, %f2630, %f3324;
	mul.f32 	%f3296, %f2631, %f3324;
	mul.f32 	%f3297, %f2632, %f3324;
	mul.f32 	%f3298, %f2633, %f3324;
	mul.f32 	%f3299, %f2634, %f3324;
	mul.f32 	%f3300, %f2635, %f3324;
	mul.f32 	%f3301, %f2636, %f3324;
	mul.f32 	%f3302, %f2637, %f3324;
	mul.f32 	%f3303, %f2638, %f3324;
	mul.f32 	%f3304, %f2639, %f3324;
	mul.f32 	%f3305, %f2640, %f3324;
	mul.f32 	%f3306, %f2641, %f3324;
	mul.f32 	%f3307, %f2642, %f3324;
	mul.f32 	%f3308, %f2643, %f3324;
	mul.f32 	%f3309, %f2644, %f3324;
	mul.f32 	%f3310, %f2645, %f3324;
	mul.f32 	%f3311, %f2646, %f3324;
	mul.f32 	%f3312, %f2647, %f3324;
	mul.f32 	%f3313, %f2648, %f3324;
	mul.f32 	%f3314, %f2649, %f3324;
	mul.f32 	%f3315, %f2650, %f3324;
	mul.f32 	%f3316, %f2651, %f3324;
	mul.f32 	%f3317, %f2652, %f3324;
	mul.f32 	%f3318, %f2653, %f3324;
	mul.f32 	%f3319, %f2654, %f3324;
	mul.f32 	%f3320, %f2655, %f3324;
	mul.f32 	%f3321, %f2656, %f3324;
	mul.f32 	%f3322, %f2657, %f3324;
	.loc	1 251 12
	mov.b32 	%r539, %f3259;
	// begin inline asm
	cvt.rn.bf16.f32 %rs65, %r539;
	// end inline asm
	mov.b32 	%r540, %f3260;
	// begin inline asm
	cvt.rn.bf16.f32 %rs66, %r540;
	// end inline asm
	mov.b32 	%r541, %f3261;
	// begin inline asm
	cvt.rn.bf16.f32 %rs67, %r541;
	// end inline asm
	mov.b32 	%r542, %f3262;
	// begin inline asm
	cvt.rn.bf16.f32 %rs68, %r542;
	// end inline asm
	mov.b32 	%r543, %f3263;
	// begin inline asm
	cvt.rn.bf16.f32 %rs69, %r543;
	// end inline asm
	mov.b32 	%r544, %f3264;
	// begin inline asm
	cvt.rn.bf16.f32 %rs70, %r544;
	// end inline asm
	mov.b32 	%r545, %f3265;
	// begin inline asm
	cvt.rn.bf16.f32 %rs71, %r545;
	// end inline asm
	mov.b32 	%r546, %f3266;
	// begin inline asm
	cvt.rn.bf16.f32 %rs72, %r546;
	// end inline asm
	mov.b32 	%r547, %f3267;
	// begin inline asm
	cvt.rn.bf16.f32 %rs73, %r547;
	// end inline asm
	mov.b32 	%r548, %f3268;
	// begin inline asm
	cvt.rn.bf16.f32 %rs74, %r548;
	// end inline asm
	mov.b32 	%r549, %f3269;
	// begin inline asm
	cvt.rn.bf16.f32 %rs75, %r549;
	// end inline asm
	mov.b32 	%r550, %f3270;
	// begin inline asm
	cvt.rn.bf16.f32 %rs76, %r550;
	// end inline asm
	mov.b32 	%r551, %f3271;
	// begin inline asm
	cvt.rn.bf16.f32 %rs77, %r551;
	// end inline asm
	mov.b32 	%r552, %f3272;
	// begin inline asm
	cvt.rn.bf16.f32 %rs78, %r552;
	// end inline asm
	mov.b32 	%r553, %f3273;
	// begin inline asm
	cvt.rn.bf16.f32 %rs79, %r553;
	// end inline asm
	mov.b32 	%r554, %f3274;
	// begin inline asm
	cvt.rn.bf16.f32 %rs80, %r554;
	// end inline asm
	mov.b32 	%r555, %f3275;
	// begin inline asm
	cvt.rn.bf16.f32 %rs81, %r555;
	// end inline asm
	mov.b32 	%r556, %f3276;
	// begin inline asm
	cvt.rn.bf16.f32 %rs82, %r556;
	// end inline asm
	mov.b32 	%r557, %f3277;
	// begin inline asm
	cvt.rn.bf16.f32 %rs83, %r557;
	// end inline asm
	mov.b32 	%r558, %f3278;
	// begin inline asm
	cvt.rn.bf16.f32 %rs84, %r558;
	// end inline asm
	mov.b32 	%r559, %f3279;
	// begin inline asm
	cvt.rn.bf16.f32 %rs85, %r559;
	// end inline asm
	mov.b32 	%r560, %f3280;
	// begin inline asm
	cvt.rn.bf16.f32 %rs86, %r560;
	// end inline asm
	mov.b32 	%r561, %f3281;
	// begin inline asm
	cvt.rn.bf16.f32 %rs87, %r561;
	// end inline asm
	mov.b32 	%r562, %f3282;
	// begin inline asm
	cvt.rn.bf16.f32 %rs88, %r562;
	// end inline asm
	mov.b32 	%r563, %f3283;
	// begin inline asm
	cvt.rn.bf16.f32 %rs89, %r563;
	// end inline asm
	mov.b32 	%r564, %f3284;
	// begin inline asm
	cvt.rn.bf16.f32 %rs90, %r564;
	// end inline asm
	mov.b32 	%r565, %f3285;
	// begin inline asm
	cvt.rn.bf16.f32 %rs91, %r565;
	// end inline asm
	mov.b32 	%r566, %f3286;
	// begin inline asm
	cvt.rn.bf16.f32 %rs92, %r566;
	// end inline asm
	mov.b32 	%r567, %f3287;
	// begin inline asm
	cvt.rn.bf16.f32 %rs93, %r567;
	// end inline asm
	mov.b32 	%r568, %f3288;
	// begin inline asm
	cvt.rn.bf16.f32 %rs94, %r568;
	// end inline asm
	mov.b32 	%r569, %f3289;
	// begin inline asm
	cvt.rn.bf16.f32 %rs95, %r569;
	// end inline asm
	mov.b32 	%r570, %f3290;
	// begin inline asm
	cvt.rn.bf16.f32 %rs96, %r570;
	// end inline asm
	mov.b32 	%r571, %f3291;
	// begin inline asm
	cvt.rn.bf16.f32 %rs97, %r571;
	// end inline asm
	mov.b32 	%r572, %f3292;
	// begin inline asm
	cvt.rn.bf16.f32 %rs98, %r572;
	// end inline asm
	mov.b32 	%r573, %f3293;
	// begin inline asm
	cvt.rn.bf16.f32 %rs99, %r573;
	// end inline asm
	mov.b32 	%r574, %f3294;
	// begin inline asm
	cvt.rn.bf16.f32 %rs100, %r574;
	// end inline asm
	mov.b32 	%r575, %f3295;
	// begin inline asm
	cvt.rn.bf16.f32 %rs101, %r575;
	// end inline asm
	mov.b32 	%r576, %f3296;
	// begin inline asm
	cvt.rn.bf16.f32 %rs102, %r576;
	// end inline asm
	mov.b32 	%r577, %f3297;
	// begin inline asm
	cvt.rn.bf16.f32 %rs103, %r577;
	// end inline asm
	mov.b32 	%r578, %f3298;
	// begin inline asm
	cvt.rn.bf16.f32 %rs104, %r578;
	// end inline asm
	mov.b32 	%r579, %f3299;
	// begin inline asm
	cvt.rn.bf16.f32 %rs105, %r579;
	// end inline asm
	mov.b32 	%r580, %f3300;
	// begin inline asm
	cvt.rn.bf16.f32 %rs106, %r580;
	// end inline asm
	mov.b32 	%r581, %f3301;
	// begin inline asm
	cvt.rn.bf16.f32 %rs107, %r581;
	// end inline asm
	mov.b32 	%r582, %f3302;
	// begin inline asm
	cvt.rn.bf16.f32 %rs108, %r582;
	// end inline asm
	mov.b32 	%r583, %f3303;
	// begin inline asm
	cvt.rn.bf16.f32 %rs109, %r583;
	// end inline asm
	mov.b32 	%r584, %f3304;
	// begin inline asm
	cvt.rn.bf16.f32 %rs110, %r584;
	// end inline asm
	mov.b32 	%r585, %f3305;
	// begin inline asm
	cvt.rn.bf16.f32 %rs111, %r585;
	// end inline asm
	mov.b32 	%r586, %f3306;
	// begin inline asm
	cvt.rn.bf16.f32 %rs112, %r586;
	// end inline asm
	mov.b32 	%r587, %f3307;
	// begin inline asm
	cvt.rn.bf16.f32 %rs113, %r587;
	// end inline asm
	mov.b32 	%r588, %f3308;
	// begin inline asm
	cvt.rn.bf16.f32 %rs114, %r588;
	// end inline asm
	mov.b32 	%r589, %f3309;
	// begin inline asm
	cvt.rn.bf16.f32 %rs115, %r589;
	// end inline asm
	mov.b32 	%r590, %f3310;
	// begin inline asm
	cvt.rn.bf16.f32 %rs116, %r590;
	// end inline asm
	mov.b32 	%r591, %f3311;
	// begin inline asm
	cvt.rn.bf16.f32 %rs117, %r591;
	// end inline asm
	mov.b32 	%r592, %f3312;
	// begin inline asm
	cvt.rn.bf16.f32 %rs118, %r592;
	// end inline asm
	mov.b32 	%r593, %f3313;
	// begin inline asm
	cvt.rn.bf16.f32 %rs119, %r593;
	// end inline asm
	mov.b32 	%r594, %f3314;
	// begin inline asm
	cvt.rn.bf16.f32 %rs120, %r594;
	// end inline asm
	mov.b32 	%r595, %f3315;
	// begin inline asm
	cvt.rn.bf16.f32 %rs121, %r595;
	// end inline asm
	mov.b32 	%r596, %f3316;
	// begin inline asm
	cvt.rn.bf16.f32 %rs122, %r596;
	// end inline asm
	mov.b32 	%r597, %f3317;
	// begin inline asm
	cvt.rn.bf16.f32 %rs123, %r597;
	// end inline asm
	mov.b32 	%r598, %f3318;
	// begin inline asm
	cvt.rn.bf16.f32 %rs124, %r598;
	// end inline asm
	mov.b32 	%r599, %f3319;
	// begin inline asm
	cvt.rn.bf16.f32 %rs125, %r599;
	// end inline asm
	mov.b32 	%r600, %f3320;
	// begin inline asm
	cvt.rn.bf16.f32 %rs126, %r600;
	// end inline asm
	mov.b32 	%r601, %f3321;
	// begin inline asm
	cvt.rn.bf16.f32 %rs127, %r601;
	// end inline asm
	mov.b32 	%r602, %f3322;
	// begin inline asm
	cvt.rn.bf16.f32 %rs128, %r602;
	// end inline asm
	.loc	1 255 12
	add.s32 	%r750, %r704, %r696;
	add.s32 	%r751, %r750, %r696;
	add.s32 	%r752, %r751, %r696;
	add.s32 	%r753, %r752, %r696;
	add.s32 	%r754, %r753, %r696;
	add.s32 	%r755, %r754, %r696;
	add.s32 	%r756, %r755, %r696;
	add.s32 	%r757, %r756, %r696;
	.loc	1 256 12
	mul.wide.s32 	%rd261, %r750, 2;
	add.s64 	%rd245, %rd39, %rd261;
	mul.wide.s32 	%rd262, %r751, 2;
	add.s64 	%rd246, %rd39, %rd262;
	mul.wide.s32 	%rd263, %r752, 2;
	add.s64 	%rd247, %rd39, %rd263;
	mul.wide.s32 	%rd264, %r753, 2;
	add.s64 	%rd248, %rd39, %rd264;
	mul.wide.s32 	%rd265, %r754, 2;
	add.s64 	%rd249, %rd39, %rd265;
	mul.wide.s32 	%rd266, %r755, 2;
	add.s64 	%rd250, %rd39, %rd266;
	mul.wide.s32 	%rd267, %r756, 2;
	add.s64 	%rd251, %rd39, %rd267;
	mul.wide.s32 	%rd268, %r757, 2;
	add.s64 	%rd252, %rd39, %rd268;
	.loc	1 257 12
	setp.lt.s32 	%p124, %r688, %r45;
	setp.lt.s32 	%p125, %r687, %r45;
	setp.lt.s32 	%p126, %r686, %r45;
	setp.lt.s32 	%p127, %r685, %r45;
	setp.lt.s32 	%p128, %r684, %r45;
	setp.lt.s32 	%p129, %r683, %r45;
	setp.lt.s32 	%p130, %r682, %r45;
	setp.lt.s32 	%p131, %r681, %r45;
	.loc	1 260 12
	and.pred  	%p107, %p124, %p123;
	and.pred  	%p108, %p125, %p123;
	and.pred  	%p109, %p126, %p123;
	and.pred  	%p110, %p127, %p123;
	and.pred  	%p111, %p128, %p123;
	and.pred  	%p112, %p129, %p123;
	and.pred  	%p113, %p130, %p123;
	and.pred  	%p114, %p131, %p123;
	.loc	1 261 12
	bar.sync 	0;
	mov.b32 	%r758, {%rs65, %rs66};
	mov.b32 	%r759, {%rs67, %rs68};
	mov.b32 	%r760, {%rs69, %rs70};
	mov.b32 	%r761, {%rs71, %rs72};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r467], {%r758, %r759, %r760, %r761};
	// end inline asm
	mov.b32 	%r762, {%rs73, %rs74};
	mov.b32 	%r763, {%rs75, %rs76};
	mov.b32 	%r764, {%rs77, %rs78};
	mov.b32 	%r765, {%rs79, %rs80};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r472], {%r762, %r763, %r764, %r765};
	// end inline asm
	mov.b32 	%r766, {%rs81, %rs82};
	mov.b32 	%r767, {%rs83, %rs84};
	mov.b32 	%r768, {%rs85, %rs86};
	mov.b32 	%r769, {%rs87, %rs88};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r477], {%r766, %r767, %r768, %r769};
	// end inline asm
	mov.b32 	%r770, {%rs89, %rs90};
	mov.b32 	%r771, {%rs91, %rs92};
	mov.b32 	%r772, {%rs93, %rs94};
	mov.b32 	%r773, {%rs95, %rs96};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r482], {%r770, %r771, %r772, %r773};
	// end inline asm
	mov.b32 	%r774, {%rs97, %rs98};
	mov.b32 	%r775, {%rs99, %rs100};
	mov.b32 	%r776, {%rs101, %rs102};
	mov.b32 	%r777, {%rs103, %rs104};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r487], {%r774, %r775, %r776, %r777};
	// end inline asm
	mov.b32 	%r778, {%rs105, %rs106};
	mov.b32 	%r779, {%rs107, %rs108};
	mov.b32 	%r780, {%rs109, %rs110};
	mov.b32 	%r781, {%rs111, %rs112};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r492], {%r778, %r779, %r780, %r781};
	// end inline asm
	mov.b32 	%r782, {%rs113, %rs114};
	mov.b32 	%r783, {%rs115, %rs116};
	mov.b32 	%r784, {%rs117, %rs118};
	mov.b32 	%r785, {%rs119, %rs120};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r497], {%r782, %r783, %r784, %r785};
	// end inline asm
	mov.b32 	%r786, {%rs121, %rs122};
	mov.b32 	%r787, {%rs123, %rs124};
	mov.b32 	%r788, {%rs125, %rs126};
	mov.b32 	%r789, {%rs127, %rs128};
	// begin inline asm
	stmatrix.sync.aligned.m8n8.x4.shared.b16 [%r502], {%r786, %r787, %r788, %r789};
	// end inline asm
	bar.sync 	0;
	ld.shared.v4.u32 	{%r643, %r644, %r645, %r646}, [%r749];
	ld.shared.v4.u32 	{%r647, %r648, %r649, %r650}, [%r749+2176];
	ld.shared.v4.u32 	{%r651, %r652, %r653, %r654}, [%r749+4352];
	ld.shared.v4.u32 	{%r655, %r656, %r657, %r658}, [%r749+6528];
	ld.shared.v4.u32 	{%r659, %r660, %r661, %r662}, [%r749+8704];
	ld.shared.v4.u32 	{%r663, %r664, %r665, %r666}, [%r749+10880];
	ld.shared.v4.u32 	{%r667, %r668, %r669, %r670}, [%r749+13056];
	ld.shared.v4.u32 	{%r671, %r672, %r673, %r674}, [%r749+15232];
	.loc	1 262 5
	// begin inline asm
	@%p107 st.global.v4.b32 [ %rd245 + 0 ], { %r643, %r644, %r645, %r646 };
	// end inline asm
	// begin inline asm
	@%p108 st.global.v4.b32 [ %rd246 + 0 ], { %r647, %r648, %r649, %r650 };
	// end inline asm
	// begin inline asm
	@%p109 st.global.v4.b32 [ %rd247 + 0 ], { %r651, %r652, %r653, %r654 };
	// end inline asm
	// begin inline asm
	@%p110 st.global.v4.b32 [ %rd248 + 0 ], { %r655, %r656, %r657, %r658 };
	// end inline asm
	// begin inline asm
	@%p111 st.global.v4.b32 [ %rd249 + 0 ], { %r659, %r660, %r661, %r662 };
	// end inline asm
	// begin inline asm
	@%p112 st.global.v4.b32 [ %rd250 + 0 ], { %r663, %r664, %r665, %r666 };
	// end inline asm
	// begin inline asm
	@%p113 st.global.v4.b32 [ %rd251 + 0 ], { %r667, %r668, %r669, %r670 };
	// end inline asm
	// begin inline asm
	@%p114 st.global.v4.b32 [ %rd252 + 0 ], { %r671, %r672, %r673, %r674 };
	// end inline asm
	.loc	1 263 5
	ret;
$L__tmp1:
$L__func_end0:

}
	.file	1 "/tmp/mren/.triton/override/b1dc4d77fe7982a3c893b0717ff24abbe10420d3c8675e9fc6d7cc7f190b70e1/_kernel_matmul_fp8_block_fastacc.ttgir"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 0
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 168
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 95
.b8 109
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 102
.b8 112
.b8 56
.b8 95
.b8 98
.b8 108
.b8 111
.b8 99
.b8 107
.b8 95
.b8 102
.b8 97
.b8 115
.b8 116
.b8 97
.b8 99
.b8 99
.b8 46
.b8 116
.b8 116
.b8 103
.b8 105
.b8 114
.b8 0
.b32 .debug_line
.b8 47
.b8 116
.b8 109
.b8 112
.b8 47
.b8 109
.b8 114
.b8 101
.b8 110
.b8 47
.b8 46
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 47
.b8 111
.b8 118
.b8 101
.b8 114
.b8 114
.b8 105
.b8 100
.b8 101
.b8 47
.b8 98
.b8 49
.b8 100
.b8 99
.b8 52
.b8 100
.b8 55
.b8 55
.b8 102
.b8 101
.b8 55
.b8 57
.b8 56
.b8 50
.b8 97
.b8 51
.b8 99
.b8 56
.b8 57
.b8 51
.b8 98
.b8 48
.b8 55
.b8 49
.b8 55
.b8 102
.b8 102
.b8 50
.b8 52
.b8 97
.b8 98
.b8 98
.b8 101
.b8 49
.b8 48
.b8 52
.b8 50
.b8 48
.b8 100
.b8 51
.b8 99
.b8 56
.b8 54
.b8 55
.b8 53
.b8 101
.b8 57
.b8 102
.b8 99
.b8 54
.b8 100
.b8 55
.b8 99
.b8 99
.b8 55
.b8 102
.b8 49
.b8 57
.b8 48
.b8 98
.b8 55
.b8 48
.b8 101
.b8 49
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
	}
	.section	.debug_loc	{	}
